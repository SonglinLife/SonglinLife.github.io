{
    "version": "https://jsonfeed.org/version/1",
    "title": "Life",
    "subtitle": null,
    "icon": "https://songlinlife.top/images/favicon.ico",
    "description": "Life is not about lifestyle, it means Lithium and Ferrum.",
    "home_page_url": "https://songlinlife.top",
    "items": [
        {
            "id": "https://songlinlife.top/2022/MIT6-824%EF%BC%9ASpaner/",
            "url": "https://songlinlife.top/2022/MIT6-824%EF%BC%9ASpaner/",
            "title": "MIT6.824：Spaner",
            "date_published": "2022-03-16T01:05:47.000Z",
            "content_html": "<p>终于到了 Spanner 了，这篇文章我打算和 GFS 还有 raft 论文一样，读得精细一些，而且 TIDB 就是基于这篇论文的实现。</p>\n<h3 id=\"摘要\"><a class=\"anchor\" href=\"#摘要\">#</a> 摘要</h3>\n<blockquote>\n<p>Spanner is Google’s scalable, multi-version, globally distributed, and synchronously-replicated database.</p>\n</blockquote>\n<p>啧啧啧，开篇第一句就这么牛逼 ？是一个可扩展、全球化分布式、和同步复制的数据库。</p>\n<p>时钟 API 是实现 Spanner 的关键所在。</p>\n",
            "tags": [
                "分布式"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/MIT6-824%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/",
            "url": "https://songlinlife.top/2022/MIT6-824%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/",
            "title": "MIT6.824：分布式事务",
            "date_published": "2022-03-15T07:12:26.000Z",
            "content_html": "<h3 id=\"before-or-after-atomicity-coordinating-concurrent-threads\"><a class=\"anchor\" href=\"#before-or-after-atomicity-coordinating-concurrent-threads\">#</a> Before-or-After Atomicity: Coordinating Concurrent Threads</h3>\n<p>before-or-after 原子性指的是一个并发操作发生在另一个并发操作的之前（before）或者之后（after）对于结果并没有影响。</p>\n<blockquote>\n<p>Concurrent actions have the before-or-after property if their effect from the point of view of their invokers is the same as if the actions occurred either completely before or completely after one another.</p>\n</blockquote>\n<p>同时也提到要实现这种 before-or-after actions 的并发正确性，需要在每个 action 使用共享变量时遵循 locking protocol，说白了就是加锁。</p>\n<p>以一个转账为例：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315160439407.png\" alt=\"image-20220315160439407\" /></p>\n<p>A 账号初始有 300 元，B 账户初始为 100 元。现在有这样一个转账：</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo separator=\"true\">,</mo><mi>B</mi><mo separator=\"true\">,</mo><mn>10</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Trans(A, B, 10)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">s</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>A 账号向 B 账号转账了 10 元，同时此时有一个 C 账号，其初始金额为 290 元，并且 B 账号向 C 账号转账 25 元：</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mo separator=\"true\">,</mo><mi>C</mi><mo separator=\"true\">,</mo><mn>25</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Trans(B,C,25)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">s</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">2</span><span class=\"mord\">5</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>这两个操作可以并发执行，那么就会出现错误：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315160516865.png\" alt=\"image-20220315160516865\" /></p>\n<h3 id=\"correctness-and-serialization\"><a class=\"anchor\" href=\"#correctness-and-serialization\">#</a> Correctness and Serialization</h3>\n<p>首先必须明确：</p>\n<blockquote>\n<p>There is such a correctness concept: coordination among concurrent actions can be considered to be correct if every result is guaranteed to be one that could have been obtained by some purely serial application of those same actions.</p>\n</blockquote>\n<p>只要 actions 的结果能够被一些串行的应用所执行得到，那么这些并发操作就是正确的。</p>\n<p>我这句话其实没怎么表述清除。。。</p>\n<p>如果一个 action 仅仅由单个线程所执行，并且再执行之前是正确的，那么执行之后也一定是正确的。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315163719498.png\" alt=\"image-20220315163719498\" /></p>\n<p>当有多个 actions 同时并发，如果这些 actions 是 before-or-after 并且执行之前是 correct，那么新状态也是 correct。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315164015861.png\" alt=\"image-20220315164015861\" /></p>\n<p>这里就引出了可串行性：</p>\n<blockquote>\n<p>serializable: there exists some serial order of those concurrent transactions that would, if followed, lead to the same ending state.</p>\n</blockquote>\n<p>这里的可串行性一般指的是冲突可串行性也就是 CSR。冲突操作可以被定义为：</p>\n<blockquote>\n<p>两个数据操作 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>o</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">o_j</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">o</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 和 $ o_i$ 是一对 <em>冲突操作（conflicting operations)</em>，如果它们满足： 它们属于不同的 transaction；以及 其中至少一个操作是写操作。</p>\n</blockquote>\n<p>只要我们满足冲突操作的排序顺序和某个串行事务 schedule 一致，那么就是满足了冲突可串行性。</p>\n<h3 id=\"听课\"><a class=\"anchor\" href=\"#听课\">#</a> 听课</h3>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315194427991.png\" alt=\"image-20220315194427991\" /></p>\n<p>这里老师讲了 <code>serializable</code> ，算是明白了到底是啥。如果一系列事务（这里就是线性）执行可以得到相同结果（这里的结果指的是外部观测得到的结果）</p>\n<p>就像上面的图中所示，T1 和 T2 两个事务执行结果只有两种情况，所以其他观察到的结果就是非可串行性。</p>\n<h4 id=\"消极锁\"><a class=\"anchor\" href=\"#消极锁\">#</a> 消极锁</h4>\n<h5 id=\"simple-lock\"><a class=\"anchor\" href=\"#simple-lock\">#</a> simple Lock</h5>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315200327884.png\" alt=\"image-20220315200327884\" /></p>\n<p>简单锁就是在使用 record 之前进行加锁，知道事务结束后才会释放锁，这样有一个好处就是保证了 serializable，但是缺点也很明显，因为不能并发这就意味着其性能很差。</p>\n<h5 id=\"two-phase-locking\"><a class=\"anchor\" href=\"#two-phase-locking\">#</a> Two-Phase Locking</h5>\n<p>2PL 很简单，它就是把加锁和解锁分为了两个阶段，一个阶段只能加锁，一个阶段只能释放锁。在 2PL 协议下，每个 transaction 都会经过两个阶段：在第一个阶段里，transaction 根据需要不断地获取锁，叫做 <strong>growing phase (expanding phase)</strong>；在第二个阶段里，transaction 开始释放其持有的锁，根据 2PL 的规则，这个 transaction 不能再获得新的锁，所以它所持有的锁逐渐减少，叫做 <strong>shrinking phase (contracting phase)</strong>。</p>\n<p>2PL 可以满足 CRS 冲突一致性，这位博主给出了 2PC 一定可以满足 CRS 的证明：</p>\n<p>Transaction management：两阶段锁（two-phase locking） - 王子旭的文章 - 知乎 <span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81OTUzNTMzNw==\">https://zhuanlan.zhihu.com/p/59535337</span></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315220608819.png\" alt=\"image-20220315220608819\" /></p>\n<p>2PL 虽然允许一定程度的并发，但是 2PL 会导致死锁。</p>\n<h4 id=\"分布式事务\"><a class=\"anchor\" href=\"#分布式事务\">#</a> 分布式事务</h4>\n<h5 id=\"2pc\"><a class=\"anchor\" href=\"#2pc\">#</a> 2PC</h5>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315203835328.png\" alt=\"image-20220315203835328\" /></p>\n<p>这个 2PC 看起来简单，但还是有各种各样的情况需要考虑。</p>\n<p>2PC 协议：</p>\n<ol>\n<li>coordinate 发送命令（也就是图中的 get、put），participate 收到命令后就去申请锁。</li>\n<li>接着，coordinate 发送 prepare 指令，如果 participate 没有 fail，数据没有丢失，record 一致性完好，申请到了锁等等，participate 检查自身状态认为自己可以完成命令就返回 yes，否则返回 No。注意在 participate 返回之前，它必须先写 LOG 到磁盘 persist。participate 回复 prepare yes 之后就开始执行操作。</li>\n<li>如果有一个返回 NO，coordinate 就会认为事务失败并且让 client retry。如果 coordinate 收到了所有的 prepare yes，那么它就会把这个事务写入 LOG。之后及时 coordinate crash，它恢复之后也必须执行这个事务。</li>\n<li>接着 coordinate 发送 commit 指令，所有 participate 收到后，就释放锁，并且在 LOG 将操作修改为 commit 状态，这样即使 participate crash 了，那么它也知道自己 commit 了。participate 返回 ACK。</li>\n<li>coordinate 收到所有 ACK 之后就返回 client 事务成功。</li>\n</ol>\n<p>2PC 会导致死锁，在 prepare 阶段后如果 coordinate fail 或者 crash 之后，participate 并不会超时释放锁，它只会一直持有锁，这就导致 time-block。</p>\n<p>2PC 性能很差，一方面由于它需要很多网络，另一方面由于 participate 返回 prepare 之前必须写 LOG，同时 coordinate 发 commit 之前也必须写 LOG。</p>\n<h3 id=\"留下的问题\"><a class=\"anchor\" href=\"#留下的问题\">#</a> 留下的问题</h3>\n<p>如何将 raft 和 2PC 结合起来，使得其既可以满足事务又可以有 availability？</p>\n",
            "tags": [
                "分布式"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/MIT6-824%EF%BC%9AFrangipani-A-Scalable-Distributed-File-System/",
            "url": "https://songlinlife.top/2022/MIT6-824%EF%BC%9AFrangipani-A-Scalable-Distributed-File-System/",
            "title": "MIT6.824：Frangipani: A Scalable Distributed File System",
            "date_published": "2022-03-15T03:36:02.000Z",
            "content_html": "<p>这个内容不是重点，而且这篇论文的年纪比我还大，说实话，我读了一部分感觉，收获不大。</p>\n<h3 id=\"听课\"><a class=\"anchor\" href=\"#听课\">#</a> 听课</h3>\n<h4 id=\"challenge\"><a class=\"anchor\" href=\"#challenge\">#</a> Challenge</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315115544252.png\" alt=\"image-20220315115544252\" /></p>\n<ol>\n<li>cache 一致</li>\n<li>原子性</li>\n<li>crash recovery</li>\n</ol>\n<h4 id=\"cache-coherence\"><a class=\"anchor\" href=\"#cache-coherence\">#</a> Cache coherence</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315120915790.png\" alt=\"image-20220315120915790\" /></p>\n<h4 id=\"获得锁的过程\"><a class=\"anchor\" href=\"#获得锁的过程\">#</a> 获得锁的过程</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315143416693.png\" alt=\"image-20220315143416693\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315123136719.png\" alt=\"image-20220315123136719\" /></p>\n<h4 id=\"atomic\"><a class=\"anchor\" href=\"#atomic\">#</a> ATOMIC</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220315124144566.png\" alt=\"image-20220315124144566\" /></p>\n<p>这里是拿到所有的锁。</p>\n",
            "tags": [
                "分布式"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/%E6%96%B0%E6%97%B6%E4%BB%A3/",
            "url": "https://songlinlife.top/2022/%E6%96%B0%E6%97%B6%E4%BB%A3/",
            "title": "新时代",
            "date_published": "2022-03-14T06:33:47.000Z",
            "content_html": "<h3 id=\"新时代的主要内涵和重大意义\"><a class=\"anchor\" href=\"#新时代的主要内涵和重大意义\">#</a> 新时代的主要内涵和重大意义</h3>\n<p>历史性成就和历史性变革：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314143410767.png\" alt=\"image-20220314143410767\" /></p>\n<p>进入新时代的依据：</p>\n<ol>\n<li><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314143522931.png\" alt=\"image-20220314143522931\" /></li>\n<li><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314143538184.png\" alt=\"image-20220314143538184\" /></li>\n<li><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314143630414.png\" alt=\"image-20220314143630414\" /></li>\n<li><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314143707504.png\" alt=\"image-20220314143707504\" /></li>\n</ol>\n<p>新时代主要内涵：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314143850984.png\" alt=\"image-20220314143850984\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314143951961.png\" alt=\"image-20220314143951961\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144041361.png\" alt=\"image-20220314144041361\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144101541.png\" alt=\"image-20220314144101541\" /></p>\n<p>进入新时代的重大意义：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144236167.png\" alt=\"image-20220314144236167\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144303933.png\" alt=\"image-20220314144303933\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144325545.png\" alt=\"image-20220314144325545\" /></p>\n<h3 id=\"我国社会主要矛盾的转换\"><a class=\"anchor\" href=\"#我国社会主要矛盾的转换\">#</a> 我国社会主要矛盾的转换</h3>\n<p>我国社会主要矛盾的转换的依据</p>\n<p>理论依据：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144609858.png\" alt=\"image-20220314144609858\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144636855.png\" alt=\"\" /></p>\n<p>我国社会主要矛盾变化的新表述：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144704119.png\" alt=\"image-20220314144704119\" /></p>\n<p>实践依据：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144813151.png\" alt=\"image-20220314144813151\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144823476.png\" alt=\"image-20220314144823476\" /></p>\n<p>主要矛盾的历次变化：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144906765.png\" alt=\"image-20220314144906765\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144914288.png\" alt=\"image-20220314144914288\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144930332.png\" alt=\"image-20220314144930332\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314144945649.png\" alt=\"image-20220314144945649\" /></p>\n<h3 id=\"我国仍处于并将长期处于社会主义初级阶段\"><a class=\"anchor\" href=\"#我国仍处于并将长期处于社会主义初级阶段\">#</a> 我国仍处于并将长期处于社会主义初级阶段</h3>\n<p>社会主义初级阶段理论的主要内容：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145449581.png\" alt=\"image-20220314145449581\" /></p>\n<p>社会主义发展的长期性和阶段性：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145554777.png\" alt=\"image-20220314145554777\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145611358.png\" alt=\"image-20220314145611358\" /></p>\n<p>我国是最大发展中国家的国际地位没有变：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145651562.png\" alt=\"image-20220314145651562\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145712025.png\" alt=\"image-20220314145712025\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145732926.png\" alt=\"image-20220314145732926\" /></p>\n<p>党在社会主义初级阶段的基本路线：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145828831.png\" alt=\"image-20220314145828831\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145852582.png\" alt=\"image-20220314145852582\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145918552.png\" alt=\"image-20220314145918552\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145935586.png\" alt=\"image-20220314145935586\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314145952669.png\" alt=\"image-20220314145952669\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150006922.png\" alt=\"image-20220314150006922\" /></p>\n<h3 id=\"中国特色社会主义政治理论和制度\"><a class=\"anchor\" href=\"#中国特色社会主义政治理论和制度\">#</a> 中国特色社会主义政治理论和制度</h3>\n<p>中国特色社会主义政治理论：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150559520.png\" alt=\"image-20220314150559520\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150613747.png\" alt=\"image-20220314150613747\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150630631.png\" alt=\"image-20220314150630631\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150659271.png\" alt=\"image-20220314150659271\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150708876.png\" alt=\"image-20220314150708876\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150726215.png\" alt=\"image-20220314150726215\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150810846.png\" alt=\"image-20220314150810846\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150834035.png\" alt=\"image-20220314150834035\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150851684.png\" alt=\"image-20220314150851684\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314150914474.png\" alt=\"image-20220314150914474\" /></p>\n<p>中国特色社会主义政治制度：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151014465.png\" alt=\"image-20220314151014465\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151043278.png\" alt=\"image-20220314151043278\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151101926.png\" alt=\"image-20220314151101926\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151406265.png\" alt=\"image-20220314151406265\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151434072.png\" alt=\"image-20220314151434072\" /></p>\n<h3 id=\"用更加健全的制度体系保证人民当家作\"><a class=\"anchor\" href=\"#用更加健全的制度体系保证人民当家作\">#</a> 用更加健全的制度体系保证人民当家作</h3>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151601718.png\" alt=\"image-20220314151601718\" /></p>\n<p>人民当家作主：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151626519.png\" alt=\"image-20220314151626519\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151641314.png\" alt=\"image-20220314151641314\" /></p>\n<p>人民当家作主的内涵：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151712254.png\" alt=\"image-20220314151712254\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151727548.png\" alt=\"image-20220314151727548\" /></p>\n<p>为什么坚持人民当家作主：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151753281.png\" alt=\"image-20220314151753281\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314151806862.png\" alt=\"image-20220314151806862\" /></p>\n<p>社会主义民主政治制度的优势：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152259011.png\" alt=\"image-20220314152259011\" /></p>\n<p>社会主义民主政治制度的保证：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152348489.png\" alt=\"image-20220314152348489\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152400703.png\" alt=\"image-20220314152400703\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152414689.png\" alt=\"image-20220314152414689\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152430910.png\" alt=\"image-20220314152430910\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152447716.png\" alt=\"image-20220314152447716\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152549458.png\" alt=\"image-20220314152549458\" /></p>\n<h3 id=\"全面依法治国建设社会主义法治国家\"><a class=\"anchor\" href=\"#全面依法治国建设社会主义法治国家\">#</a> 全面依法治国，建设社会主义法治国家</h3>\n<p>明确全面推进依法治国：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153031519.png\" alt=\"image-20220314153031519\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152905367.png\" alt=\"image-20220314152905367\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314152917105.png\" alt=\"image-20220314152917105\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153106201.png\" alt=\"image-20220314153106201\" /></p>\n<p>坚定不移走中国特色社会主义法治道路：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153303968.png\" alt=\"image-20220314153303968\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153331059.png\" alt=\"image-20220314153331059\" /></p>\n<p>建设社会主义法治国家:</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153406778.png\" alt=\"image-20220314153406778\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153422299.png\" alt=\"image-20220314153422299\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153439128.png\" alt=\"image-20220314153439128\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153506113.png\" alt=\"image-20220314153506113\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153532435.png\" alt=\"image-20220314153532435\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153546328.png\" alt=\"image-20220314153546328\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153606840.png\" alt=\"image-20220314153606840\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153635660.png\" alt=\"image-20220314153635660\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153652041.png\" alt=\"image-20220314153652041\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314153700237.png\" alt=\"image-20220314153700237\" /></p>\n",
            "tags": [
                "琐事"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/MIT6-824-Aurora/",
            "url": "https://songlinlife.top/2022/MIT6-824-Aurora/",
            "title": "MIT6.824: Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases",
            "date_published": "2022-03-14T04:04:58.000Z",
            "content_html": "<h3 id=\"aurora\"><a class=\"anchor\" href=\"#aurora\">#</a> Aurora</h3>\n<p>就是 cloud scale 级别的数据库。</p>\n<h3 id=\"durability-at-scale\"><a class=\"anchor\" href=\"#durability-at-scale\">#</a> DURABILITY AT SCALE</h3>\n<h4 id=\"replication-and-correlated-failures\"><a class=\"anchor\" href=\"#replication-and-correlated-failures\">#</a> Replication and Correlated Failures</h4>\n<p>在分布式系统中，经常会遇到各种故障，并且这些故障有些是独立的，有些是相关的。一个思路来设计容错的 replicated system 就是使用 quorum-based voting protocol。</p>\n<p>为了满足一致性，也就是能读到最新的数据，一个读操作获得的票数 <code>Vr</code>  与一个写操作获得的票数 <code>Vw</code>  的和必须是 <code>Vr + Vw &gt; V</code> 。这个不等式很好理解，满足了这个不等式那么读操作必然能够读到最新的数据。同时我们也需要满足 <code>Vw &gt; V/2</code> 。</p>\n<p>但是通常为了容错的做法是：</p>\n<blockquote>\n<p>A common approach to tolerate the loss of a single node is to replicate data to (V = 3) nodes and rely on a write quorum of 2/3 (Vw = 2) and a read quorum of 2/3 (Vr = 2).</p>\n</blockquote>\n<p>但是作者认为这个数量不是足够的。文章中给出了一个容错设计：</p>\n<p>每个 AZ（Availability Zone）中有两个 replicas，并且需要维持 3 个 AZ。整个系统就有 6 票，写操作需要 4 票，读操作需要 3 票。这样实现写容错就只需要一个 AZ + 一个额外节点完好，写操作只需要满足 2 个 AZ 完好就行。</p>\n<h3 id=\"the-log-is-the-database\"><a class=\"anchor\" href=\"#the-log-is-the-database\">#</a> THE LOG IS THE DATABASE</h3>\n<h3 id=\"听课\"><a class=\"anchor\" href=\"#听课\">#</a> 听课</h3>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314194722941.png\" alt=\"image-20220314194722941\" /></p>\n<p>EBS 用 chain 复制的方法</p>\n<h4 id=\"db-tutorial\"><a class=\"anchor\" href=\"#db-tutorial\">#</a> DB tutorial</h4>\n<p>只写 log record 不写 b tree，这样省时间</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314200345601.png\" alt=\"image-20220314200345601\" /></p>\n<h4 id=\"rds\"><a class=\"anchor\" href=\"#rds\">#</a> RDS</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314202015099.png\" alt=\"image-20220314202015099\" /></p>\n<h4 id=\"ft-goals\"><a class=\"anchor\" href=\"#ft-goals\">#</a> F.T. Goals</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314202734284.png\" alt=\"image-20220314202734284\" /></p>\n<h4 id=\"quorum\"><a class=\"anchor\" href=\"#quorum\">#</a> Quorum</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314212029093.png\" alt=\"image-20220314212029093\" /></p>\n",
            "tags": [
                "分布式"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/linux/MIT6-S081%EF%BC%9AIntroduction/",
            "url": "https://songlinlife.top/2022/linux/MIT6-S081%EF%BC%9AIntroduction/",
            "title": "MIT6.S081：Introduction",
            "date_published": "2022-03-14T01:55:18.000Z",
            "content_html": "<h3 id=\"写在开头的话\"><a class=\"anchor\" href=\"#写在开头的话\">#</a> 写在开头的话</h3>\n<p>MIT6.824 这门课我已经做完一半内容了，而且 lab 也只剩下最后的 lab4。所以我在想似乎现在是时候开启新的副本了。</p>\n<p>我知道上一个副本我还没打通关，而且 MIT6.824 是大副本，整个 3 月份加上读论文，我也并没有很大把握能够把这么课程干掉。我的规划里面这么课程是作为我的核心课程，自然也要精细一些。但是 6.S081 的难度并没有那么大，如果时间安排的好的话，在 4 月中旬我是可以结束这门课的。</p>\n<p>关于我为什么要学这么课。</p>\n<p>一个很大的原因就是直接关于操作系统的知识太薄弱了，但是如果要走向数据库、分布式方向就必须和底层也就是操作系统打交道。所以操作系统不得不学。这门课程也是一个本科生课程，我的学习能力还是有点自信的。</p>\n<p>MIT6.824 和 MIT6.S081，争取全部在四月中结束。然后就是愉快的 CPP 康复训练了。五月争取学完 CMU445。如果那时候没有找到实习就接着学 CMU721。</p>\n<p>ok，你可以做到的对吧？</p>\n<h3 id=\"命令\"><a class=\"anchor\" href=\"#命令\">#</a> 命令</h3>\n<h4 id=\"fork\"><a class=\"anchor\" href=\"#fork\">#</a> fork</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314104858521.png\" alt=\"image-20220314104858521\" /></p>\n<p>fork 在子进程中返回 0，在父进程中返回子进程的 pid。</p>\n<h4 id=\"exec\"><a class=\"anchor\" href=\"#exec\">#</a> exec</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314105419719.png\" alt=\"image-20220314105419719\" /></p>\n<p>exec 就是将当前进程内存清空，执行新的命令。这里就是会去执行 echo 命令。但是需要注意的是，这里是清空当前进程的内存，而不是另开一个新进程。如果 exec 执行成功，exec 会执行 exit (0)。如果 exec 执行失败，就会执行 exec 接下来的代码，也就是 printf。</p>\n<h4 id=\"forkexec\"><a class=\"anchor\" href=\"#forkexec\">#</a> forkexec</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314110105319.png\" alt=\"image-20220314110105319\" /></p>\n<p>当前进程 fork 了一个子进程，子进程使用 exec 清空了当前进程内存，并且执行了 echo。如果 exec 执行失败，才会执行下面的 printf 和 exit。</p>\n<p>而父进程使用 wait 等待子进程传回结束的 status。如果子进程执行 exec 结束，也就是 exit (0)，返回 status 0。如果执行 exec 失败就会是 exit (1)。</p>\n<h4 id=\"redirect\"><a class=\"anchor\" href=\"#redirect\">#</a> redirect</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220314111428220.png\" alt=\"image-20220314111428220\" /></p>\n<p>这里将子进程的 output 重定向 output.txt。主要，fork 会复制父进程的所有文件描述符，但是维护了一个复制的文件描述符表，这意味着即使我们修改了子进程的文件描述符，不会影响到父进程。</p>\n",
            "tags": [
                "Linux"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/GrimoireLab%EF%BC%9A%E5%A1%AB%E5%9D%91%E8%AE%B0/",
            "url": "https://songlinlife.top/2022/GrimoireLab%EF%BC%9A%E5%A1%AB%E5%9D%91%E8%AE%B0/",
            "title": "GrimoireLab：填坑记",
            "date_published": "2022-03-13T08:19:54.000Z",
            "content_html": "<p>用于记录我在使用 GrimoireLab 遇到的各种问题。</p>\n<h3 id=\"搭建\"><a class=\"anchor\" href=\"#搭建\">#</a> 搭建</h3>\n<p>在阿里云的云服务器上搭建的实例。使用的是香港的节点，所以拉取镜像的速度会很快。</p>\n<h4 id=\"遇到的坑点\"><a class=\"anchor\" href=\"#遇到的坑点\">#</a> 遇到的坑点</h4>\n<p>ElasticSearch 无法启动</p>\n<blockquote>\n<pre><code>elasticsearch_1  | max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\n</code></pre>\n</blockquote>\n<p>报错信息是虚内存不够用，无法启动 Elastic。解决办法：</p>\n<figure class=\"highlight go\"><figcaption data-lang=\"go\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>sysctl <span class=\"token operator\">-</span>w vm<span class=\"token punctuation\">.</span>max_map_count<span class=\"token operator\">=</span><span class=\"token number\">262144</span></pre></td></tr></table></figure><h3 id=\"食用方法\"><a class=\"anchor\" href=\"#食用方法\">#</a> 食用方法</h3>\n<h4 id=\"git\"><a class=\"anchor\" href=\"#git\">#</a> git</h4>\n<p>git 不需要配置 config 文件，只要在 projects.json 文件中给出地址就行了：</p>\n<figure class=\"highlight json\"><figcaption data-lang=\"JSON\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token property\">\"OpenDigger\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>      <span class=\"token property\">\"meta\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token property\">\"title\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"OpenDigger\"</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>      <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>      <span class=\"token property\">\"git\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>          <span class=\"token string\">\"https://github.com/X-lab2017/open-digger\"</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>          <span class=\"token string\">\"https://github.com/X-lab2017/open-digger-website\"</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>  <span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>效果图：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220313165938014.png\" alt=\"image-20220313165938014\" /></p>\n<p>可以点击添加 filter。</p>\n<p>注意：如果是 private repo 需要在 url 中指定</p>\n",
            "tags": [
                "xlab"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-lab3-KV-Service/",
            "url": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-lab3-KV-Service/",
            "title": "MIT6.824: lab3 KV Service",
            "date_published": "2022-03-07T05:51:07.000Z",
            "content_html": "<p>终于到了 Lab3 了，写一个 KV 服务🐍</p>\n<h3 id=\"要求\"><a class=\"anchor\" href=\"#要求\">#</a> 要求</h3>\n<p>lab3 需要构建一个 fault-tolerance key/value storage service。用到之前 lab2 写的 Raft library。</p>\n<ol>\n<li>\n<p>三个 api 接口： <code>Put(key, value)</code> ,  <code>Append(key, arg)</code> , and  <code>Get(key)</code> 。如果 key 不存在， <code>Get(key)</code>  返回空 string，并且 <code>append</code>  与 <code>put</code>  操作等价。</p>\n</li>\n<li>\n<p>each client talks to the service through a  <code>Clerk</code>  with Put/Append/Get methods.</p>\n</li>\n<li>\n<p>实现强一致性。</p>\n</li>\n<li>\n<p>达成效果</p>\n</li>\n<li>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220309191901863.png\" alt=\"image-20220309191901863\" /></p>\n</li>\n</ol>\n<h3 id=\"part-a\"><a class=\"anchor\" href=\"#part-a\">#</a> Part A</h3>\n<p>每一个 kv server 都关联了一个 raft peer。</p>\n<p>实现 <code>Put</code> 、 <code>Append</code> 、 <code>Get</code> 。kvserver 先 raft 提交这三个 operation，raft log 写这三个操作的序列。</p>\n<p>kv server 由 raft 决定应该执行什么 operation。</p>\n<p><code>Clerk</code>  并不知道谁是 leader，因此如果 Clerk 发送 RPC 到错的 kvserver，或者不能到达这个 kvserver，那么 Clerk 需要重新发送到另一个 kvserver。</p>\n<p>如果这个命令 commit 之后，那么 raft 会 apply command，亏 server 会先执行的结果返回给 Clerk。</p>\n<p>如果 operation 没有被 commit，那么 server 发送一个 error，然后 <code>Clerk</code>  需要重试。</p>\n<h4 id=\"我的思考\"><a class=\"anchor\" href=\"#我的思考\">#</a> 我的思考</h4>\n<p>client 通过 clerk 发送三种 operation，这三种 operation 只能被 leader 来执行。只要是 leader apply 的 operation 一定是 commit，这毫无疑问。现在的问题是如何让 kvserver 来检查这个操作是执行的呢？</p>\n<p>Put 和 Append 操作只能被执行一次不能被多次执行，这一点需要注意。</p>\n<p>对于 command，需要设计一个格式，能够让 kvserver 知道 operation 是什么。因为 command 就是一个 string。</p>\n<p>按照要求也就是说 client 如果没有执行成功某个 operation 就会一直被阻塞。</p>\n<p>我关于 PutAppend 的考虑，因为操作需要去除重复，因为 client 需要并发。所以不能</p>\n<h3 id=\"raft实现线性一致性\"><a class=\"anchor\" href=\"#raft实现线性一致性\">#</a> Raft 实现线性一致性</h3>\n<p>多用户并发（每个 client 只是调用一个请求）</p>\n<blockquote>\n<p>It's OK to assume that a client will make only one call into a Clerk at a time.</p>\n</blockquote>\n<p>提升中也说了，可以假设 client 每一次只是 call 一次。</p>\n<blockquote>\n<p>it's OK in this case for the server and client to wait indefinitely until the partition heals.</p>\n</blockquote>\n<p>也就是说可以让这个 wait 无限制等下去。（等 commit 可以不限时间）</p>\n<p>但是我们能不能操作一下？搞一个超时？</p>\n<p>我没头绪的时候，看到了 Raft 博士论文，真的感动啊。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturespicturesimage-20220307222045412.png\" alt=\"image-20220307222045412\" /></p>\n<p>按照这个参数写 RPC 就行了。</p>\n<h4 id=\"去重复\"><a class=\"anchor\" href=\"#去重复\">#</a> 去重复</h4>\n<p>我们假定每一个 client 每一次只是执行（call）一个操作，并且如果执行失败的话，那么它会阻塞住，并且一直执行这个请求。</p>\n<p>这样去重复就很简单了，我们只需要在 server 端维护一个 lastComandID 就行了，数据结构为 map []</p>\n<h3 id=\"39号更新\"><a class=\"anchor\" href=\"#39号更新\">#</a> 3.9 号更新</h3>\n<p>最近一个非常严重的 bug 卡了我一天，怎么都没办法处理好。是关于线性一致性的，我一直没有怎么理解线性一致性这就导致我这个 lab 做得很痛苦。</p>\n<p>先看一下 raft 作者对线性一致性的理解：</p>\n<blockquote>\n<p>In linearizability, each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response. This is a strong form of consistency that is simple for clients to reason about, and it disallows commands being processed multiple times.</p>\n</blockquote>\n<p>注意这个 exactly once， at some point。也就是说所有操作都只能执行一次，并且是原子性瞬时的。这似乎有些奇怪，因为我们明明可以执行多次的，因为当有请求到 kv server 时候我们就进行了一次写 raft log，然后因为超时原因我们又一次向 raft 发送了请求，有一次写了一次 raft log。所以在 apply 阶段，为了实现这个 exactly once 我们需要对操作进行去重复，保证所有操作只能执行一次。</p>\n<p>但是问题还没结束，去重真的保证了线性一致性吗？注意作者这句话：<strong>at some point between its invocation and its response. **  between its invocation and its response. 是关键所在，也就是说我们的执行是要发生在调用和返回之间的。但是在上面的描述中，我们是怎么操作的？如果当超时就</strong>重新发送请求 **。这意味着那个超时的请求已经结束了，它没有在调用和返回之间执行！</p>\n<p>来看下面这个场景：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220309100623892.png\" alt=\"image-20220309100623892\" /></p>\n<p>这里有三个 client，并发发送请求。现在我们把问题简单化，只是对 log 中的一个变量 x 进行考虑，它初始为空，A1 表示向 x Append 1。R 表示读这个变量 x。</p>\n<p>注意！这里我的线段表示 client<strong> 发起某一个请求到结束的时间</strong>，这段时间内 client 可能因此超时等原因多次发送重复的请求，知道最终收到答复。</p>\n<p>因为 KV server 首先执行了 A1、A2。所以这时候 client1 先读取 x，它读到了 x 的值为 12。但是因为 rpc 调用等原因，这个读取到的值没有返回给 client。那么 client 肯定会重新发送读请求的。但是因为<strong>去重</strong>，我们不能再执行这个读操作了，于是我们把这个读到的结果存起来。等下一次 client1 发送读请求的时候直接发送存好的结果。</p>\n<p>ok，client3 此时执行了 A3，x 的值变为 123，那么 client2 再读后就读到了 123. 并且直接返回给了 client2。</p>\n<p>过了一会，client1 也读到了结果，x 值为 12。</p>\n<p><strong>于是这就没有了线性一致性了，因为 client1 读到了一个旧的值！</strong></p>\n<p>为什么会出现这个情况，因为我们违背了：</p>\n<p><strong>each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response)</strong></p>\n<p>client 的读操作持续了很长一段时间，而不是 execute instantaneously。</p>\n<p>我的思考就是，读请求不能进行去重，也就是说它只能在当前的 KV request 得到处理。</p>\n<p>其实教授在课上讲到过这种场景，Read 操作返回旧值并不一定破化了一致性。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220316094851952.png\" alt=\"image-20220316094851952\" /></p>\n<p>比如 C2 的 read 操作，在箭头处后面它会返回 4，但是在箭头处之前它可能返回 3。rpc 有网络延迟，所以客户端是可以接收到旧值的，但是这并不意味着破坏了线性一致性，因为这个旧值不是 server 希望的而是 client 看到了。</p>\n<h3 id=\"310号更新\"><a class=\"anchor\" href=\"#310号更新\">#</a> 3.10 号更新</h3>\n<p>遇到问题，10 次测试里面总是会一次测试莫名奇妙丢失 log，导致数据在不同的 kv 上同步失败。。。很失败，我打了一天的 debug，还是没有找到原因。</p>\n<p>我知道问题出在我的 raft 层，但是即使我查看了很久，我也没有找我我的 raft 层问题出在哪里。。。。</p>\n<ol>\n<li>leader 选举可能有点问题，导致选举了不应该成为 leader 的节点，致使覆盖了后续的日志。但是这个可能性不大</li>\n<li>AppendEntries 出错，没有 commit 的 log entries 认为 committed 了，这就导致后续这个丢失。</li>\n</ol>\n<p>问题是我没有找到这个导致怎么情况。。。就这样吧，心累了。。。</p>\n<p>而且 3B 是真的过不了，必须代码重构，把 raft 重新写一遍。。。感觉心好累啊。</p>\n<h3 id=\"raft重构\"><a class=\"anchor\" href=\"#raft重构\">#</a> Raft 重构</h3>\n<p>参考代码：</p>\n<h3 id=\"312号更新\"><a class=\"anchor\" href=\"#312号更新\">#</a> 3.12 号更新</h3>\n<p>愉快打过 lab3</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220312193359692.png\" alt=\"image-20220312193359692\" /></p>\n",
            "tags": [
                "分布式",
                "MIT6.824"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-Object-Storage-on-CRAQ-High-throughput-chain-replication-for-read-mostly-workloads/",
            "url": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-Object-Storage-on-CRAQ-High-throughput-chain-replication-for-read-mostly-workloads/",
            "title": "MIT6.824: Object Storage on CRAQ High-throughput chain replication for read-mostly workloads",
            "date_published": "2022-03-06T11:19:37.000Z",
            "content_html": "<h3 id=\"简介\"><a class=\"anchor\" href=\"#简介\">#</a> 简介</h3>\n<p>说白了就是 CR 的加强版，将读请求分摊到链上的每个 replicas，搭配 zookeeper 实现了分布式容错机制。</p>\n<h3 id=\"基本模型\"><a class=\"anchor\" href=\"#基本模型\">#</a> 基本模型</h3>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220306192043325.png\" alt=\"image-20220306192043325\" /></p>\n<p>CRAQ (Chain Replication with Apportioned Queries), 只会提供两个原语，读和写。</p>\n<p>两种一致性：</p>\n<p><strong>强一致性</strong>：所有读操作都能读到最新的数据。</p>\n<p><strong>最终一致性</strong>：所有节点 apply write order 相同，但是读操作可能读到 stale data。</p>\n<p>CRAQ 能够保证强一致性。</p>\n<h4 id=\"chain-replication\"><a class=\"anchor\" href=\"#chain-replication\">#</a> Chain Replication</h4>\n<p>这张图足够解释 Chain Replication：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220307111243918.png\" alt=\"image-20220307111243918\" /></p>\n<p>所有的 write request 都必须通过 head 来处理，head 处理 write，也就是修改对应的 object。注意每个 object 都有一个 <code>version</code> 。修改 object 后 version 也会随之改变。当 head 收到了 write 请求之后就会将这个 write operation 通过 chain 传递下去。在 tail 处才会 commit 这个 write，并且把 reply 返回给 client。</p>\n<h4 id=\"chain-replication-with-apportioned-queries\"><a class=\"anchor\" href=\"#chain-replication-with-apportioned-queries\">#</a> Chain Replication with Apportioned Queries</h4>\n<p>Object 在 replicas 上有不同的 version，每个 version 有两种状态： <code>clean</code>  与 <code>dirty</code> 。</p>\n<p><code>clean</code> ：当 object 被创建时，它的对应 version 是 clean。只有 clean 状态 version 才能被读取。</p>\n<p><code>dirty</code> ：当 object 被修改后 version 后增加。如果节点不是 tail，那么它需要将这个 version 的 object append。并将这个 version 标为 <code>dirty</code> 。</p>\n<p><strong>只有 tail 的 committed 才能将 version 从 dirty 转换为 clean</strong></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220307113000838.png\" alt=\"image-20220307113000838\" /></p>\n<p>Figure 3 很好地解释了 Query 方式，对于一个 Query 来说：</p>\n<ol>\n<li>如果查询的这个 object 的最新的 version 是 clean，那么就将这个 object 返回。</li>\n<li>如果对应的 version 是 dirty，那么 replicas 向 Tail 询问哪个 version 是 clean 的。tail 返回 clean 的 version 号。</li>\n<li>replicas 将对应 clean version 的 object 返回给 client。</li>\n</ol>\n<p><strong>注意：如果一个 version 被确认为 clean，它会删除之前所有 dirty version。但 clean version 之后的却不会被删除！</strong></p>\n<p>将像图 3 所示，V1 被确认为 clean version，它会删除 V0（如果有 V0 的话），而不会删除 V2。</p>\n<p>通过这样的机制就可以让每一个 replicas 承担 read，并且还保证了<strong>强一致性</strong>。</p>\n<h3 id=\"scaling-craq\"><a class=\"anchor\" href=\"#scaling-craq\">#</a> Scaling CRAQ</h3>\n<p>这一块有点模糊，大致是看懂了。。。</p>\n<p>一个 object 的 identifier 有两个组成</p>\n<p><code>chain identifier</code> ：决定有哪些节点会构成这条链</p>\n<p><code>key identifier</code> ：决定这个 object 在这条链中的唯一标识</p>\n<h4 id=\"链放置策略\"><a class=\"anchor\" href=\"#链放置策略\">#</a> 链放置策略</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220307122506089.png\" alt=\"image-20220307122506089\" /></p>\n<p>第一种：指定确定数量的 num_datacenters 将会构成链，总共有 chain_size 的链，使用一致性 hash 来决定 datacenter identifier。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220307122714827.png\" alt=\"image-20220307122714827\" /></p>\n<p>第二种：链的头部是 dc1，链的尾部是 dcN。严格按照这个顺序定义链。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220307122908296.png\" alt=\"image-20220307122908296\" /></p>\n<p>第二种：虽然链的顺序定义了，但是每个 datacenter 能放置的链数量也是限定的。</p>\n<h4 id=\"craq-within-a-datacenter\"><a class=\"anchor\" href=\"#craq-within-a-datacenter\">#</a> CRAQ within a Datacenter</h4>\n<p>一个 datacenter 中如何选择或者说处理多个链通过该 datacenter。这里有两种方法：</p>\n<ul>\n<li>一致性 hash。</li>\n<li>类似于 GFS 的 membership management。</li>\n</ul>\n<h4 id=\"craq-across-multiple-datacenters\"><a class=\"anchor\" href=\"#craq-across-multiple-datacenters\">#</a> CRAQ Across Multiple Datacenters</h4>\n<blockquote>\n<p>CRAQ’s ability to read from any node improves its latency when chains stretch across the wide-area.</p>\n</blockquote>\n<p>CRAQ 能够显著降低延迟，当 CRAO across wide area。</p>\n<h3 id=\"后面部分待续\"><a class=\"anchor\" href=\"#后面部分待续\">#</a> 后面部分待续</h3>\n<h3 id=\"听课\"><a class=\"anchor\" href=\"#听课\">#</a> 听课</h3>\n",
            "tags": [
                "分布式"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-zookeeper/",
            "url": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-zookeeper/",
            "title": "MIT6.824: ZooKeeper: Wait-free coordination for Internet-scale systems",
            "date_published": "2022-03-05T02:13:48.000Z",
            "content_html": "<h3 id=\"lock-free-wait-free-以及-cas\"><a class=\"anchor\" href=\"#lock-free-wait-free-以及-cas\">#</a> lock-free wait-free 以及 CAS</h3>\n<p>读这篇文章需要一点关于 wait-free、lock-free 和 CAS 的前置知识。</p>\n<p>知乎有一篇文章写了关于 wait-free 和 lock-free 的理解：对 wait-free 和 lock-free 的理解 - 我的猪猪呢的文章 - 知乎 <span class=\"exturl\" data-url=\"aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNDI5MjEzMjM=\">https://zhuanlan.zhihu.com/p/342921323</span></p>\n<p>对于有锁算法：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305122831221.png\" alt=\"image-20220305122831221\" /></p>\n<p>可以看到在 <code>slip3</code>  没有任何线程 <code>MakeProgress</code> 。这就是因为 T2 在 slip2 加了锁，然后可能因为 IO 操作，它在 slips 不再占用 CPU，但由于操作还没有完成，因此 T2 并没有释放锁，导致 T1 和 T3 在 slip3 没有申请到锁也就没有执行。</p>\n<p>lock-free：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305123155562.png\" alt=\"image-20220305123155562\" /></p>\n<p>可以保证每个 slip 都能有线程 MakeProgress。这个怎么实现呢？可以通过 CAS（Compare And Swap）。</p>\n<p>CAS 有三个操作参数：</p>\n<ol>\n<li>内存位置 V</li>\n<li>上一次从内存中读到的值 A</li>\n<li>新的值 B</li>\n</ol>\n<p>CAS 的操作过程：将内存位置 V 的值与 A 进行比较，如果相等说明没有其他线程来修改这个值，于是把内存 V 的值更新为 B（swap），如果不相等，说明 V 上的值被修改过了。于是程序回到开始，继续执行比较置换操作。直到成功结束 loop。因此任意时间内，总有进程能够 MakeProgress，而且时间足够长的话所有进程都能执行完。</p>\n<p>而 wait-free 能提供更高的保证：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305150003064.png\" alt=\"image-20220305150003064\" /></p>\n<p>任意的一个 slip 下，每条线程都能够 MakeProgress。</p>\n<p>Wait-free 被定义为算法在完成最终目标之前，每一个操作都能在有限步内实现。这里的第一个 operation 可以理解为本文的 Make Progress，step 可以理解为 Slip，当线程的每一个 Slip 都在 Make Progress 时，那么针对一个特定的算法就一定能在有限个 Slip 内完成，这是显而易见的。</p>\n<h3 id=\"简介\"><a class=\"anchor\" href=\"#简介\">#</a> 简介</h3>\n<blockquote>\n<p>Zookeeper，a service for coordinating processes of distributed applications.</p>\n</blockquote>\n<p>说白了就是一个协调处理分布式 process 的服务。</p>\n<h3 id=\"the-zookeeper-service\"><a class=\"anchor\" href=\"#the-zookeeper-service\">#</a> The ZooKeeper service</h3>\n<h4 id=\"znode\"><a class=\"anchor\" href=\"#znode\">#</a> Znode</h4>\n<p>znode 就类似与文件系统，每个节点都是一个 zonde，每个 znode 能可能有 parent 或者 children。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305151252501.png\" alt=\"image-20220305151252501\" /></p>\n<h4 id=\"watch\"><a class=\"anchor\" href=\"#watch\">#</a> watch</h4>\n<p>当 client issue 一个 watch flag 给一个读操作。那么当这个读取的信息发生了改变的时候，就会触发 watch 给这个 client 发送一个 notification。因为我们并不需要告知 client，而只要告知发生了 change 这个事实，因此在一个时间段 change 了什么，发生了几次 change 都不需要考虑。</p>\n<p>值得注意的是，watch 操作是一次性的，执行完通知 watch 就结束了，client 的下一次读可以接着加上一个 watch flag。</p>\n<p>同时，如果当前 replicas 宕机了，client 会转向另一个 replicas，之前所有注册的 watch 都失效，因为 watch table 丢失了。</p>\n<p>这里有一篇文章详细介绍了 zookeeper 的 watch：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9sdnFpdXNoaS5naXRodWIuaW8vMjAyMC8wMS8yMi96b29rZWVwZXItMi8=\">https://lvqiushi.github.io/2020/01/22/zookeeper-2/</span></p>\n<p>这张图也写的很好：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/pictureszk-watch-eventType.png\" alt=\"watch-eventType\" /></p>\n<p>当非 None 事件出现时就会触发 watch，并且 watch 会失效。</p>\n<h4 id=\"zookeeper-guarantees\"><a class=\"anchor\" href=\"#zookeeper-guarantees\">#</a> ZooKeeper guarantees</h4>\n<p>zookeeper 有两个基本的 ordering guarantee：</p>\n<p><code>Linearizable write</code> ：zookeeper 保证所有关于 update（也就是写）的 request 都是 serializabel。（注意它并不包括读）</p>\n<p><code>FIFO client order</code> ：来自一个 client 所有的 request 执行顺序遵从 client 发送这些 request 的顺序，也就是 FIFO。</p>\n<h4 id=\"关于configuration\"><a class=\"anchor\" href=\"#关于configuration\">#</a> 关于 configuration</h4>\n<p>zookeeper 使用 leader/worker 机制，这就意味着当 leader 改变的时候，有大量的 configuration 参数也需要改变。但是必须满足：</p>\n<ul>\n<li>当 leader 开始对 configuration make change，其他 processes 不应该使用这些已经改变的 configuration。</li>\n<li>如果 leader 在 configuration 整个 update 完了之前就 dead 了，我们不希望这个 partial configuration 被使用。</li>\n</ul>\n<p>对于第一个要求，可以使用分布式锁来控制，即 leader 写的时候其他 worker 不应该读。但是分布式锁可能导致性能下降，所以 zookeeper 提出了一个 <code>ready znode</code>  机制。</p>\n<p>leader 会创建一个 <code>ready</code>  znode，并且其他 process 都只能通过读这个 znode 来更新 configuration。如果这个 leader 需要更新 configuration，就把 <code>ready</code>  删除、更新数据并且创建 ready。需要注意的 ready 并不是只有一个，论文中提到可能需要 update 5000 个不同的 znode。</p>\n<p>但是论文中也提到了一个问题，如果一个 client 读到了 ready exist，但是 new leader 在此之后对 ready 进行了 change，那么 client 就会在 change in progress 时候读到数据。</p>\n<p>解决办法：设置 watch flag。zookeeper 可以保证在 make change 之后，在 client 读到新的数据之前一定能够收到 notification。</p>\n<h4 id=\"sync\"><a class=\"anchor\" href=\"#sync\">#</a> Sync</h4>\n<p>sync 类似于 Flush 命令，注意 ZooKeeper guarantees，zookeeper 保证 order。在后文里有写这个 read order 指的不只是执行顺序 FIFO，还要有不能回头读的意思。</p>\n<p>sync 做的就是把 read 命令先挂起，然后 replicas 向 leader 拉取新的数据，注意这个新数据并不指的完全新，只是到 read 需要的那个 point 就行了。</p>\n<h4 id=\"examples-of-primitives\"><a class=\"anchor\" href=\"#examples-of-primitives\">#</a> Examples of primitives</h4>\n<h5 id=\"configuration-management\"><a class=\"anchor\" href=\"#configuration-management\">#</a> Configuration Management</h5>\n<p>Zookeeper 需要使用到动态的 configuration，但是它实现这个的方式知识将 config 存在在一个 znode 中，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>c</mi></msub></mrow><annotation encoding=\"application/x-tex\">z_c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">c</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 。processes 启动后会读取 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>c</mi></msub></mrow><annotation encoding=\"application/x-tex\">z_c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">c</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 获得配置，并且设置 watch flag。当 configuration 修改之后，process 可以获得 notification 并且读取最新的 configuration。</p>\n<h5 id=\"rendezvous\"><a class=\"anchor\" href=\"#rendezvous\">#</a> Rendezvous</h5>\n<p>有时候，client 需要启动一个 master process 和一些 worker process，但是这个 starting processes 是被调度器完成的，因此 client 并没有办法预先知道 master 暴露的端口和地址。Zookeeper 使用一个 Rendezvous znode，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding=\"application/x-tex\">z_r</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 来解决这一问题。master 启动之后，会把自己提供服务的端口和地址写到 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>r</mi></msub></mrow><annotation encoding=\"application/x-tex\">z_r</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 中。worker 启动之后就读取这个 znode，并且设置 watch flag。</p>\n<h5 id=\"group-membership\"><a class=\"anchor\" href=\"#group-membership\">#</a> Group Membership</h5>\n<p>这个很好理解，说白了就是为一个 group 设置一个 znode，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding=\"application/x-tex\">z_g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>。当这个 group 的 process 启动时，就会在这个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding=\"application/x-tex\">z_g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 下创建子 znode。这些 znode 是 ephemeral node，如果 client fail 或者 session 关闭后，zookeeper 会自动回收。因此，要得到 group 信息只需要看 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>z</mi><mi>g</mi></msub></mrow><annotation encoding=\"application/x-tex\">z_g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 的子节点就行了。同时还可以设置一个 watch flag，当 group information change 时候接收通知。</p>\n<h4 id=\"锁\"><a class=\"anchor\" href=\"#锁\">#</a> 锁</h4>\n<h5 id=\"简单锁\"><a class=\"anchor\" href=\"#简单锁\">#</a> 简单锁</h5>\n<p>最简单的实现锁的方式就是创建一个 ephemeral znode。如果 client 创建该文件成功就意味着获得锁，如果删除该文件就意味着释放锁。但是这就一个问题，如果有很多用户同时在申请锁，那就无法满足按申请顺序获得锁。（Herd Effect）</p>\n<h5 id=\"simple-locks-without-herd-effect\"><a class=\"anchor\" href=\"#simple-locks-without-herd-effect\">#</a> Simple Locks without Herd Effect</h5>\n<p>它的实现方式很巧妙：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305205542785.png\" alt=\"image-20220305205542785\" /></p>\n<ol>\n<li>申请锁时，先创建 <code>znode l</code>  下的子 znode。并且设置 Sequential 和 ephemeral。</li>\n<li>获取 <code>znode l</code>  的所有 children。</li>\n<li>如果 n 是 C 中最低的 znode，那么获得锁。</li>\n<li>查看 n 之前的那个 znode p。</li>\n<li>如果 p 存在那么 wait，否则跳转到 2。</li>\n</ol>\n<p>这里需要注意，最后跳转是跳转到步骤 2，因为 znode p 对应的那个 client 如果关闭了 session，那么系统会自动回收这个 znode p。也就是说 znode p 不存在并不意味这 p 刚刚释放了锁。</p>\n<h4 id=\"readwrite-locks\"><a class=\"anchor\" href=\"#readwrite-locks\">#</a> Read/Write Locks</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305210202530.png\" alt=\"image-20220305210202530\" /></p>\n<p>看图说话罢了。</p>\n<h3 id=\"zookeeper-implementation\"><a class=\"anchor\" href=\"#zookeeper-implementation\">#</a> ZooKeeper Implementation</h3>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305155146341.png\" alt=\"image-20220305155146341\" /></p>\n<p>这块内容没怎么看懂。。。但是这个<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mi>x</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">zxid</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span></span></span></span> 听课的时候大致听懂了，这个<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mi>x</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">zxid</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span></span></span></span> 就是为了防止出现 read back 操作。</p>\n<p>每一个 read 操作都在一个<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mi>x</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">zxid</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span></span></span></span> 上进行，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mi>x</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">zxid</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span></span></span></span> 只能随着读操作增大，当切换 replicas 的时候，read 操作也要在相同的<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mi>x</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">zxid</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span></span></span></span> 上进行。</p>\n<h3 id=\"听课\"><a class=\"anchor\" href=\"#听课\">#</a> 听课</h3>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305173809911.png\" alt=\"image-20220305173809911\" /></p>\n<p>zookeeper 并没有实现线性一致性，它允许读到 stale data。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220307102215737.png\" alt=\"image-20220307102215737\" /></p>\n<p>zookeeper 实现 mini-transaction：</p>\n<p><code>data, v = GETDATA(p, watch)</code></p>\n<p><code>SETDATA(p, data+1, v)</code></p>\n<p>zookeeper 通过 getdata 会返回当前 data 的 version，setdata 如果 replicas 中 dataversion 一致才能 setdata。</p>\n<p>这就实现了一个 mini-transaction</p>\n",
            "tags": [
                "分布式",
                "MIT6.824"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/grimoireLab-%E5%B9%B3%E5%8F%B0%E7%AE%A1%E7%90%86%E7%BB%84%E4%BB%B6/",
            "url": "https://songlinlife.top/2022/grimoireLab-%E5%B9%B3%E5%8F%B0%E7%AE%A1%E7%90%86%E7%BB%84%E4%BB%B6/",
            "title": "grimoireLab: 平台管理组件",
            "date_published": "2022-02-27T12:18:08.000Z",
            "content_html": "<h3 id=\"mordred\"><a class=\"anchor\" href=\"#mordred\">#</a> Mordred</h3>\n<blockquote>\n<p>SirMordred is the tool used to coordinate the execution of the GrimoireLab platform, via two main configuration files, the  <code>setup.cfg</code>  and  <code>projects.json</code> , which are summarized in their corresponding sections.</p>\n</blockquote>\n<p>也就是说这个工具是管理平台用的。主要的配置文件有两个 <code>Setup.cfg</code>  和 <code>Projects.json</code> 。</p>\n<h4 id=\"setupcfg\"><a class=\"anchor\" href=\"#setupcfg\">#</a> Setup.cfg</h4>\n<p>这个配置文件用于管理 <code>GrimoireLab</code>  的 processes。比如设置 log 日志放在哪，SortingHat 和 ElasticSearch 怎么访问，也可以设置 Perceval 的访问令牌。</p>\n<h4 id=\"projectsjson\"><a class=\"anchor\" href=\"#projectsjson\">#</a> Projects.json</h4>\n<blockquote>\n<p>The projects.json aims at describing the repositories grouped by a project that will be shown on the dashboards.</p>\n</blockquote>\n<p>也就是说这个配置文件用于配置 repos 是如何被 grouped by a project 然后在 dashboard 上显示的。</p>\n<h3 id=\"grimoirelab-toolkit\"><a class=\"anchor\" href=\"#grimoirelab-toolkit\">#</a> grimoirelab-toolkit</h3>\n<p>grimoirelab projects 经常用到的包，比如处理日期的函数。</p>\n<h3 id=\"grimoirelab-bestiary\"><a class=\"anchor\" href=\"#grimoirelab-bestiary\">#</a> grimoirelab-bestiary</h3>\n<blockquote>\n<p>A tool to visually manage software development ecosystems description.</p>\n</blockquote>\n<p>用于直观描述软件开发生态的工具。</p>\n<h3 id=\"hatstall\"><a class=\"anchor\" href=\"#hatstall\">#</a> Hatstall</h3>\n<blockquote>\n<p>Hatstall is a web interface for <span class=\"exturl\" data-url=\"aHR0cDovL2dpdGh1Yi5jb20vZ3JpbW9pcmVsYWIvc29ydGluZ2hhdA==\">SortingHat</span> databases developed mainly with <span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuZGphbmdvcHJvamVjdC5jb20v\">Django</span></p>\n</blockquote>\n<p>就是 SortingHat 的 Web 接口。</p>\n<p>SortingHat 做的工作：</p>\n<ul>\n<li>they might be using several usernames in the same data source (i.e. different emails for git commits)</li>\n<li>to get a whole view, you need to take into account their contribution in different data sources (git, issues, chats, etc.). You need to merge multiple usernames under a single unique identity</li>\n<li>they might be working for several organizations during project life</li>\n</ul>\n<p>而 Hatstall 就是处理 multi-identites 更简单的工具。</p>\n",
            "tags": [
                "xlab"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/grimoireLab-%E6%95%B0%E6%8D%AE%E6%B6%88%E8%B4%B9%E7%BB%84%E4%BB%B6/",
            "url": "https://songlinlife.top/2022/grimoireLab-%E6%95%B0%E6%8D%AE%E6%B6%88%E8%B4%B9%E7%BB%84%E4%BB%B6/",
            "title": "grimoireLab: 数据消费组件",
            "date_published": "2022-02-27T11:26:10.000Z",
            "content_html": "<h3 id=\"kibiter\"><a class=\"anchor\" href=\"#kibiter\">#</a> Kibiter</h3>\n<p><code>Kibiter</code>  就是<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuZWxhc3RpYy5jby9jbi9raWJhbmEv\"> Kibana</span> 的定制化 fork。</p>\n<p>下图为 kibana：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220227192947022.png\" alt=\"image-20220227192947022\" /></p>\n<p>可以看到这个就是一个仪表盘。。。</p>\n<h4 id=\"功能\"><a class=\"anchor\" href=\"#功能\">#</a> 功能</h4>\n<h5 id=\"面板菜单\"><a class=\"anchor\" href=\"#面板菜单\">#</a> 面板菜单</h5>\n<p><img data-src=\"https://camo.githubusercontent.com/5719bb8ee2bd3caadb0293bc6c2a4e56c8571ec10dc173b2886d548b32614281/68747470733a2f2f692e696d6775722e636f6d2f36684f346145562e706e67\" alt=\"img\" /></p>\n<h5 id=\"new-visualization-plugins\"><a class=\"anchor\" href=\"#new-visualization-plugins\">#</a> New visualization plugins</h5>\n<p><code>Kibiter</code>  默认安装了一些可视化插件，比如 Network plugin，允许用户通过图方式查看数据。</p>\n<h3 id=\"sigils\"><a class=\"anchor\" href=\"#sigils\">#</a> sigils</h3>\n<p>这个就是一个 Json 文件夹，包含了所有关于 kibana dashboard 的信息。</p>\n<ul>\n<li>Original indexes where the information come from.</li>\n<li>Searches on those indexes that provide a sub-set of the information.</li>\n<li>Widgets either built on top of the original indexes or on top of the searches.</li>\n<li>Final panels that are an aggregation of several widgets.</li>\n</ul>\n<p>这就说就是关于 Dash Board 的配置。</p>\n<h3 id=\"kidash\"><a class=\"anchor\" href=\"#kidash\">#</a> Kidash</h3>\n<p>这个就是管理 Kibana-related dashboards 的命令行工具。</p>\n<h3 id=\"manuscripts\"><a class=\"anchor\" href=\"#manuscripts\">#</a> Manuscripts</h3>\n<p>这个组件用于自动生成 enrich 数据的 Report。</p>\n",
            "tags": [
                "xlab"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/grimoireLab-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/",
            "url": "https://songlinlife.top/2022/grimoireLab-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/",
            "title": "grimoireLab: 数据增强相关组件",
            "date_published": "2022-02-27T09:39:07.000Z",
            "content_html": "<h3 id=\"grimoireelk\"><a class=\"anchor\" href=\"#grimoireelk\">#</a> GrimoireELK</h3>\n<p><code>GrimoireELK</code>  就是一个数据增强组件，这个组件基于 ElasticSearch。这个组件的作用有两个。</p>\n<ol>\n<li>存储 <code>perceval</code>  获得的数据，这样就不用反复拉取。</li>\n<li>对原来的数据进行加工和 enrich，使其能被 K 从 bit 而使用。</li>\n</ol>\n<p>关于 raw 数据和 enrich 数据可以直接查看 https://github.com/chaoss/grimoirelab-elk，这里不多描述。</p>\n<h3 id=\"ceres\"><a class=\"anchor\" href=\"#ceres\">#</a> Ceres</h3>\n<p><code>Ceres</code>  就是一个数据解析工具，他负责解析从 <code>perceval</code>  获取得到的数据。</p>\n<p>它的工作逻辑如下：</p>\n<h4 id=\"eventize\"><a class=\"anchor\" href=\"#eventize\">#</a> Eventize</h4>\n<p><code>perceval</code>  会产生 JSON 格式的数据，而 ceres 做的就是 <code>split</code> 。通过 <code>eventizing</code> ，ceres 将 json 文件辨析为 Pandas 的 DataFrame 格式。ceres 有两种解析程度，这个后续再看。</p>\n<h4 id=\"format\"><a class=\"anchor\" href=\"#format\">#</a> Format</h4>\n<p>format 功能就是格式转换，比如将时间从 string 转换为 Date 格式。</p>\n<h4 id=\"filter\"><a class=\"anchor\" href=\"#filter\">#</a> Filter</h4>\n<p>filter 可以用于过滤某一行的信息。</p>\n<h4 id=\"data-enrich\"><a class=\"anchor\" href=\"#data-enrich\">#</a> Data Enrich</h4>\n<p>数据增强，虽然我不知道它是怎么做到的。</p>\n<h3 id=\"sorting-hat\"><a class=\"anchor\" href=\"#sorting-hat\">#</a> Sorting Hat</h3>\n<blockquote>\n<p>A tool to manage identities.</p>\n</blockquote>\n<p>这是简介对于 Sorting Hat 的描述，也就是说它是处理 identities 的。但是简介好像没有说这个 identities 到底是什么，好像只说有唯一 uuid，对于每一独特的 identity 可以定义一个 profile。</p>\n<p>identity 可以对应不同时间段的从属关系。</p>\n<p>Sorting Hat 使用 Perceval 的检索数据，并把获得的 identities 保存到数据库中。</p>\n<p>这玩意的用法我还是没怎么搞懂，identites 和 profile 到底怎么搞？</p>\n",
            "tags": [
                "xlab"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-lab2-Raft/",
            "url": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-lab2-Raft/",
            "title": "MIT6.824: lab2 Raft",
            "date_published": "2022-02-26T03:38:28.000Z",
            "content_html": "<p>首先我是读了论文之后再写这个 lab 的，但 raft 论文的内容太多了，只能慢慢一点点看。现在还是先把 lab 完成。</p>\n<p>强烈安利：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvbFViVkJWenZOVnhoZ2JjSFFCYmtrUQ==\">https://mp.weixin.qq.com/s/lUbVBVzvNVxhgbcHQBbkkQ</span></p>\n<p>先上图</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220305162951465.png\" alt=\"image-20220305162951465\" /></p>\n<p>4 个小题全部通关，并且并行测试 1000 次无出错。</p>\n<h3 id=\"part-2a\"><a class=\"anchor\" href=\"#part-2a\">#</a> Part 2A</h3>\n<p><strong>任务要求</strong>：实现选举算法和心跳包。如果旧的 leader 没有问题就让旧的 leader 继续执行，如果旧的 leader 有问题那么就选举新的 leader。</p>\n<p>这意味着我们不用设置 normal term，只要考虑 leader fail 这种情况。</p>\n<p><strong>任务提示</strong>：</p>\n<ul>\n<li>完成 <code>raft.go</code></li>\n<li>完成 <code>RequestVote</code>   RPC</li>\n<li>实现 <code>AppendEntries</code>  RPC</li>\n<li>注意不要发生同时进行选举的情况。</li>\n<li>要求 leader 发生心跳包每秒不超过 10 次。</li>\n<li>要求旧的 leader fail 5 秒内完成选举。</li>\n<li>因为 tester 旅程每秒只能发送 10 次心跳，所以 election timeout 必须要大于 paper 里描述的 150-300。</li>\n</ul>\n<h3 id=\"part2b\"><a class=\"anchor\" href=\"#part2b\">#</a> Part2B</h3>\n<h4 id=\"33更新\"><a class=\"anchor\" href=\"#33更新\">#</a> 3.3 更新</h4>\n<p>我真的想干死他妈了，折腾了好几天终于无伤打过 LAB2B，运行 100 次也没有出错，这里面的坑点真的很多。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220303115450291.png\" alt=\"image-20220303115450291\" /></p>\n<p>首先需要明确 committed 是如何被确认的：</p>\n<p>对于 leader 来说：<strong>nextIndex -&gt; matchIndex -&gt; commitIndex -&gt; applyIndex</strong></p>\n<blockquote>\n<p>If there exists an N such that N &gt; commitIndex, a majority of matchIndex[i] ≥ N, and log[N].term == currentTerm:  set commitIndex = N</p>\n</blockquote>\n<p>刚开始我也搞不懂这个 <code>matchIndex</code>  是什么东西，leader 是通过 check majority matchIndex 并且如果该 log entry 属于当前 term 就确认 committed。</p>\n<p>对于 follower: **preLogIndex -(匹配成功)&gt; len (logs) -compart with leadercommitted&gt; commitIndex -&gt; applyIndex **</p>\n<p><strong>commitIndex = min(len(logs) , leaderCommitted</strong></p>\n<p>对于 follower 来说可以是 leader 告知 committed，也可以是通过 append log 后自己确认，总之这个过程逻辑自洽。</p>\n<p>但是这个有一个很严重的坑点，会导致时不时出现 <strong>index out of range</strong> 这个错误。这个错误其实有在 raft guide 上写明，但是我当时并没有看懂，导致执行 100 次总有几次报这个 out of range 错误。。。。</p>\n<p>出现这个问题的原因就是 follower 应用了 stale AppendEntries PRC，然后给 leader 发送了 reply success = true。因为 leader 会重复发送 AppendEntries PRC，如果某个 AppendEntries PRC 返回 true 后，leader 就会执行：<strong>nextIndex[server] += len(args.entries)</strong>，这就导致有时候 leader 会将相同的 AppendEntries PRC 应用两次后，nextIndex [server] += len (args.entries) 也执行两次。最后导致 nextIndex [server] 要超过了 log 的长度。</p>\n<p>解决方法：</p>\n<figure class=\"highlight go\"><figcaption data-lang=\"go\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>last <span class=\"token operator\">:=</span> rf<span class=\"token punctuation\">.</span>logs<span class=\"token punctuation\">[</span>args<span class=\"token punctuation\">.</span>PrevLogIndex<span class=\"token operator\">+</span><span class=\"token number\">1</span> <span class=\"token punctuation\">:</span> <span class=\"token function\">len</span><span class=\"token punctuation\">(</span>rf<span class=\"token punctuation\">.</span>logs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">// 难点在于如何判断旧的 rpc</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">if</span> <span class=\"token function\">len</span><span class=\"token punctuation\">(</span>last<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token function\">len</span><span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">.</span>Entries<span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">len</span><span class=\"token punctuation\">(</span>last<span class=\"token punctuation\">)</span> <span class=\"token operator\">!=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">&#123;</span> <span class=\"token comment\">// 判断要 append 的 log entries 是不是已经 append 上了</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    flag <span class=\"token operator\">:=</span> <span class=\"token boolean\">true</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token operator\">:=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> <span class=\"token function\">len</span><span class=\"token punctuation\">(</span>last<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token keyword\">if</span> last<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>TermNumber <span class=\"token operator\">!=</span> args<span class=\"token punctuation\">.</span>Entries<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>TermNumber <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>            flag <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>            <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token keyword\">if</span> flag <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        reply<span class=\"token punctuation\">.</span>XTerm <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">2</span> <span class=\"token comment\">// 表示这个是过时的 rpc</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        <span class=\"token keyword\">return</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>还有一个很严重的坑点，就是选举超时重置，它会导致<strong> rejoin of partitioned leader <em>...</em></strong> 这个测试时不时失败，这是因为选举不当，导致 cluster 没有及时选举出 leader。</p>\n<p>这里需要注意，什么时候才会重置 election timeout：</p>\n<ul>\n<li>当 follower 升级为 candidate 时会重置。</li>\n<li>当 follower 投出自己的一票时会重置。</li>\n<li>当 follower 接受到 leader 的 appendEntries PRC 时会重置。</li>\n</ul>\n<p>第一种情况很简单，就是因为超时才会升级为 candidate，所以成为 candidate 后必须重置。</p>\n<p>第二情况有些复杂，如果一个 leader 或者 candidate 接受到一个 vote request，其中 rf.currentTerm &lt; args.Term。这说明该 leader 或者 candidate 已经 out of date，必须强制转换为 follower，注意，强制转换为 follower 并不代表它可以重置它自身的 election timeout。只有满足严格选举要求，把自己的票投出去后才可以重置。follower 在每一个 Term 有且只有一张选票！但 server 进行 term 提升后就可以分配一张新选票。</p>\n<p>第三种情况其实和第二种情况类似，appendEntries PRC 只能由 leader 发出，一旦当前 server 确认其自身的 currentTerm &lt;= args.Term 就会把选举时间重置。</p>\n<p>只要注意这两个问题：旧 AppendEntries 和 election timeout，就可以轻松 pass all test 了！</p>\n<h3 id=\"part-2c\"><a class=\"anchor\" href=\"#part-2c\">#</a> Part 2C</h3>\n<p>这个 lab 要求我们实现 persistence。</p>\n<h4 id=\"33更新-2\"><a class=\"anchor\" href=\"#33更新-2\">#</a> 3.3 更新</h4>\n<p>无伤通关，就很 nice！</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220303191029815.png\" alt=\"image-20220303191029815\" /></p>\n<p>执行超过 100 次，仍然这么坚挺！太佩服我自己了，嘿嘿😄</p>\n<p>这个基本思路很简单，就是实现 <code>persist</code> ，然后把 <code>persist()</code>  插入到 persist state 变换的地方，通过 figure 2 不难知道：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220303172723928.png\" alt=\"image-20220303172723928\" /></p>\n<p>只要这三个变量改变的时候，我们就插入 <code>persist</code> 。</p>\n<p>但是这里也有一个坑点，这就 appendEntries RPC 会因为网络出错，下面我来描述一下出错情境：</p>\n<p>首先明确，因为我们会不断重复发 AppendEntries RPC，这就导致 follower 需要检查，这个 AppendEntries RPC 是否已经过时，如果过时就返回 false，如果没过时就返回 true</p>\n<h5 id=\"testfigure8unreliable2c报错返回true的appendentriesrpc丢失问题\"><a class=\"anchor\" href=\"#testfigure8unreliable2c报错返回true的appendentriesrpc丢失问题\">#</a> TestFigure8Unreliable2C 报错，返回 true 的 AppendEntriesRPC 丢失问题</h5>\n<p>原因在于，leader 首先发送了一份 entries，follower 通过 AppendEntries 收到了这份 Entries。follower 检查到这个 AppendEntries 中携带的 Entries 没有被 Append 到自己的 logs 中，于是它 append，并返回 true。但是这个本该返回 true 的 AppendEntries RPC 因为网络没有返回（永久丢失，或者返回很慢，leader 超时不再接受），leader 于是又重新发送了一份相同的 Entries。follower 检查到这个 AppendEntries 中携带的 Entries 之前已经 Append 过了，于是它返回给 leader false。leader 收到 false 后于是重复发送，于是整个系统陷入了 <code>living lock</code> 。</p>\n<p><strong>解决办法</strong>：当 follower 检测到 stale AppendEntriesRPC 时，它告诉 leader，这个 RPC 过时了，并且同时返回 follower 自己的 <code>len(logs)</code>  也就是 <code>XIndex</code> 。leader 检查到过时的 RPC，它通过检查 <code>reply.XIndex == len(args.Entris) + rf.nextIndex[server]</code>  ，如果满足说明它没有接受到那个返回 true 的 AppendEntries，于是它将 <code>rf.nextIndex[server] = reply.Xindex</code> 。至此，我们就能够解决返回 true 的 AppendEntriesRPC 丢失问题。</p>\n<h5 id=\"unreliable-churn-out-of-range-问题\"><a class=\"anchor\" href=\"#unreliable-churn-out-of-range-问题\">#</a> unreliable churn out of range 问题</h5>\n<p>原因在于，网络太混乱了。在上面我们提到，返回 true 的 AppendEntriesRPC 会因为网络丢失，然后 leader 一直陷入活锁。我们的解决办法是告诉 leader，这个 AppendEntries 过时了，leader 来检查需不需要修改 <code>rf.nextIndex</code> 。</p>\n<p>但是！！！</p>\n<p>你有没有想过，因为网络很乱，如果 stale appendEntriesRPC 要比那个返回 true 的 AppendEntriesRPC 先返回呢？leader 对于 stale AppendEntriesRPC，它会认为自己之前的那个返回 True 的 AppendEntriesRPC 丢失了。于是 leader 修改了自己的 nextIndex。但是那个返回 true 的 AppendEntries 因为网络还可以，最后还是成功返回了。leader 于是又修改了自己的 <code>nextIndex</code> 。这就导致了 out of range 的出现，并且这个问题是偶发性的，因为这属于网络中的极端情况。</p>\n<p>我们的解决办法也很简单，如果 leader 要修改自己的 nextIndex，必须满足：</p>\n<p><code>reply.XIndex == len(args.Entries) + rf.nextIndex[server]</code></p>\n<h5 id=\"testfigure8unreliable2c稀有out-of-range\"><a class=\"anchor\" href=\"#testfigure8unreliable2c稀有out-of-range\">#</a> TestFigure8Unreliable2C 稀有 out of range</h5>\n<p>因为我的 log 日志的 index 是从 1 开始的，于是在初始化时候，我会默认将 index = 0 设置为 0， applyindex =0 , commitIndex= 0。</p>\n<p>但是在设置 nextIndex，因为日志不匹配，我就需要遍历找到最优的 Index，但是这里我的遍历条件是：</p>\n<p><code>for i = len(rf.logs) - 1; i &gt;= 0; i--</code></p>\n<p>这就会导致在很罕见的情况下，i 会被归为 0，而我们用 0 给 nextIndex 赋值，就导致 preLogIndex 变成了 - 1。这就会出现 out of range。但这个情况很少见，100 次里能出现 1 次？</p>\n<p>改成： <code>for i = len(rf.logs) - 1; i &gt;= 1; i--</code>  就行了。</p>\n<p><strong>都是细节！真的太细了。。。。</strong></p>\n<h3 id=\"part2d\"><a class=\"anchor\" href=\"#part2d\">#</a> Part2D</h3>\n<p>这个 lab 要求我们完成 log compaction。</p>\n<p>需要实现 <code>Snapshot(index int, snapshot []byte)</code> ，tester 来定期调用。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220303200330913.png\" alt=\"image-20220303200330913\" /></p>\n<h4 id=\"无伤通关34更新\"><a class=\"anchor\" href=\"#无伤通关34更新\">#</a> 无伤通关！！！！！（3.4 更新）</h4>\n<p>终于无伤通关了 lab2 了，真的服了我自己了。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220304214412025.png\" alt=\"image-20220304214412025\" /></p>\n<p>批量测试还在跑，但是问题不大，嘿嘿。</p>\n<p>2D 其实很简单，就是需要将原来的索引进行替换，我的选择是写两个转换函数：</p>\n<figure class=\"highlight go\"><figcaption data-lang=\"go\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">func</span> <span class=\"token punctuation\">(</span>rf <span class=\"token operator\">*</span>Raft<span class=\"token punctuation\">)</span> <span class=\"token function\">Convert</span><span class=\"token punctuation\">(</span>index <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span> <span class=\"token builtin\">int</span> <span class=\"token punctuation\">&#123;</span> </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>\t<span class=\"token keyword\">return</span> index <span class=\"token operator\">-</span> rf<span class=\"token punctuation\">.</span>lastIncludedIndex</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">func</span> <span class=\"token punctuation\">(</span>rf <span class=\"token operator\">*</span>Raft<span class=\"token punctuation\">)</span> <span class=\"token function\">Reconvert</span><span class=\"token punctuation\">(</span>index <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span> <span class=\"token builtin\">int</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>\t<span class=\"token keyword\">return</span> index <span class=\"token operator\">+</span> rf<span class=\"token punctuation\">.</span>lastIncludedIndex</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>在刚开始我的想法是，因为每一次做 snap 都会切断 logs，于是需要考虑处理空 log 日志的情况，但是其实没有必要，如果考虑空 log 会导致整个代码逻辑变得非常复杂。</p>\n<p>解决方法：每一次做 snapshot 得到新的 log 时候，我们在 logs 前面插入一个空 log entry，并且它的 term 等于 <code>lastIncludeTerm</code> 。于是我们之前写的代码就只要一点点改变。</p>\n<p>第二个坑点就是，选择什么时候调用 Installsnapshot。我最开始想的是在 sendAppendEntries 在这个函数的返回逻辑部分进行处理，但是由于 RPC 是建立在 UDP 上的，整个网络异常混乱，导致可能多个 Installsnapshot 调用之间顺序很乱，不利于我们的思考。</p>\n<p>解决办法：把调用 Installsnapshot 放到 heartbeat 函数里，让每一次 heartbeat 考虑要不要调用 installsnapshot。</p>\n<h4 id=\"installsnapshot-rpc\"><a class=\"anchor\" href=\"#installsnapshot-rpc\">#</a> Installsnapshot RPC</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220304215521240.png\" alt=\"image-20220304215521240\" /></p>\n<p>按照要求实现这个 RPC 就行了，需要注意因为整个网络不可信，我们需要验证这个 InstallSnapshot 是否已经过时。</p>\n<h3 id=\"遗留的问题\"><a class=\"anchor\" href=\"#遗留的问题\">#</a> 遗留的问题</h3>\n<p>这是我做这个 lab 发现的一个很奇妙的现象，但我完成了 2D 的时候，回过头我检查之前的 ABC 测试，发现 B 测试中的 *😗 RPC byte count 测试出现 RPC byte count failed。</p>\n<p>这个问题是因为，整个网络是 UDP 的，会出现这么一种情况：RPC 包发出去后，因为 UDP 广播，被自己立即接受了，并返回。这样就使得整个网络变得异常臃肿。</p>\n<p>这个 Bug 出现的原因是因为，我在代码中增加了这样一个逻辑，一旦检查到自己发出的 RPC 包被自己接收后就 return。</p>\n<p>但是我至今也没搞懂，为什么不行！</p>\n<p>这个问题，未来的我，你可以解决的对吧？😏</p>\n<h3 id=\"raft-basic\"><a class=\"anchor\" href=\"#raft-basic\">#</a> Raft Basic</h3>\n<p>将 servers 分为三种状态：leader、follower 和 candidate。</p>\n<p>follower 是消极的，他们只能响应 leader 或者 candidate 的请求。candidate 是选举时产生的。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226123046018.png\" alt=\"image-20220226123046018\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226123113136.png\" alt=\"image-20220226123113136\" /></p>\n<p>就像图中描述的，term 分为两个阶段 election 和 normal。每个 term 都有对于的 current term number。<strong>如果 candidate 或者 leader 发现他的 term 过时了，那么他们会自动变为 follows。</strong></p>\n<p>RequestVote RPCs 在选举时由 candidate 进行初始化，并且 AppendEntries RPCs 被 leader 初始化用于复制 log entries 和提供 heartbeat（就是空的 AppendEntries）。</p>\n<p><strong>记住 raft 中的节点其实就是状态机！</strong></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220228220844868.png\" alt=\"image-20220228220844868\" /></p>\n<p>这里我有一个想法，因为是 state machine，由于 raft 层记录了 lastApply，而且 state machine 只能 apply committed entries。所有的机子都会 apply 相同的 committed entries。因此这里可能会出现重复响应情况，比如 client 发送请求给 leader，leader committed 请求后返回给 client 响应之后马上挂掉了，raft 通过选举产生了新的 leader，那么新的 leader 可能会让 state machine 重复 apply，也就是重复发送响应。</p>\n<p><strong>但是这没有问题！重复是 tcp 层应该解决的问题。</strong></p>\n<p>LastApply 永远应该小于或等于 committed index！</p>\n<h3 id=\"leader选举\"><a class=\"anchor\" href=\"#leader选举\">#</a> Leader 选举</h3>\n<p>server 开启，初始状态为 follower，并且如果他收到 <code>leader</code>  或者 <code>candidate</code>  的有效 RPCs，那么就会一直维持 follower。如果 follower 在 election timeout 内没有收到任何 RPCs，那么他就会增加 current term 并且成为 candidate 开启选举。</p>\n<h4 id=\"follower\"><a class=\"anchor\" href=\"#follower\">#</a> follower</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226150941941.png\" alt=\"image-20220226150941941\" /></p>\n<h4 id=\"candidate\"><a class=\"anchor\" href=\"#candidate\">#</a> candidate</h4>\n<p>通过 RequestVote RPC 同时向集群中所有的 server 要求投票。</p>\n<h5 id=\"requestvote-rpc的结构\"><a class=\"anchor\" href=\"#requestvote-rpc的结构\">#</a> RequestVote RPC 的结构：</h5>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226150031701.png\" alt=\"image-20220226150031701\" /></p>\n<h5 id=\"candidate需要做的\"><a class=\"anchor\" href=\"#candidate需要做的\">#</a> candidate 需要做的：</h5>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226150232338.png\" alt=\"image-20220226150232338\" /></p>\n<p>这里其实还少些了一个很重要的条件：</p>\n<blockquote>\n<p>Current terms are exchanged whenever servers communicate; if one server’s current term is smaller than the other’s, then it updates its current term to the larger value. If a candidate or leader discovers that its term is out of date, it immediately reverts to follower state. If a server receives a request with a stale term number, it rejects the request.</p>\n</blockquote>\n<p>也就说如果 leader 或者 candidate 发现有人的 current term number 比它的还要大，那么就自动变成 follower，这个特性很重要！</p>\n<h4 id=\"关于randomized-election-timeouts\"><a class=\"anchor\" href=\"#关于randomized-election-timeouts\">#</a> 关于 randomized election timeouts</h4>\n<p>论文中提到：</p>\n<blockquote>\n<p>raft uses randomized election timeouts to ensure that split votes are rare and that they are resolved quickly.</p>\n</blockquote>\n<p>这个一直困恼我，整个随机 election timeouts 是如何解决 split votes。因为有一段话：</p>\n<blockquote>\n<p>This spreads out the servers so that in most cases only a single server will time out; it wins the election and sends heartbeats before any other servers time out.</p>\n</blockquote>\n<p>这段话的意思是说先 timeout 的 server 会获得选举胜利。这里就有一个疑问为什么先 timeout 的 server 一定会获得选举胜利。其实要搞懂还得看 follower。follower 做了一件事：</p>\n<blockquote>\n<p>If a follower receives no communication over a period of time called the election timeout, then it assumes there is no viable leader and begins an election to choose a new leader.</p>\n</blockquote>\n<p>如果 follower 在 <code>election timeout</code>  没有收到 leader 或 candidate 的 rpc，那么它会开启选举，注意这里的超时时间是 <code>election timeout</code> 。也就是说过 leader 挂了的话，那么 <code>election timeout</code>  最小的那个机子就会先意识到，于是他成为 candidate 并且向其他 server 发送 RequestVote RPC。而 raft 的投票机制就是先来先到规则，先发起投票的那个 server 很有可能可以赢得选举。</p>\n<p>candidate 初始化也做了一件事：</p>\n<blockquote>\n<p>Each candidate restarts its randomized election timeout at the start of an<br />\nelection, and it waits for that timeout to elapse before starting the next election</p>\n</blockquote>\n<p>candidate 初始化后也会重新随机初始化这个 <code>election timeout</code> 。如果在这个阶段发生了 split vote 情况，那么 <code>election timeout</code>  最小的 candidate 就会率先超时，并且开启新的投票，于是其他 candidate 看到新的 RequestVote 中的 <code>current term</code>  大于自身的 term number，于是这些 candidate 就会自动变成 followers 并给新的 candidate 投票。于是 splitvote 问题就可以很好地解决了！</p>\n<h3 id=\"state\"><a class=\"anchor\" href=\"#state\">#</a> State</h3>\n<h4 id=\"所有的server都有的状态\"><a class=\"anchor\" href=\"#所有的server都有的状态\">#</a> 所有的 server 都有的状态</h4>\n<p><code>committedIndex</code> ：这就是 logs 中 committed highest log entry index，这个初始化为 0。</p>\n<p><code>log[]</code> ：log 初始化中会把 index 为 0 初始化，也就是后续添加 entry 的 index 都是从 1 开始。</p>\n<p><code>lastApplied</code> ：index of highes log entry applied to state machine。通过 heartbeat 发送了 entry 之后受到了 confirm，确定是 committed 之后就可以执行了。这个 lab 可能不会涉及。</p>\n<p><code>commitIndex</code> ：通过 heartbeat 得到回复，leader 就可以确认 committed 了。</p>\n<h4 id=\"leader-维护的状态\"><a class=\"anchor\" href=\"#leader-维护的状态\">#</a> leader 维护的状态</h4>\n<p><code>matchIndex[]</code> ：对于每个 server，需要复制的最高 log entry index，初始化为 0。我还没搞懂这个最高需要被复制为啥要初始化为 0。</p>\n<p><code>nextIndex[]</code> : leader 会保存下一个为 server 发送了 log entry 的 index。这里的 index 我直接设定为 log 的索引。（初始化为 <code>len(logs)</code> ）</p>\n<h3 id=\"关于54-safety\"><a class=\"anchor\" href=\"#关于54-safety\">#</a> 关于 5.4 Safety</h3>\n<p>有个大前提：leader 可以无限 append log，但是它不能通过选举然后增大自己的 term。</p>\n<h4 id=\"严格选举\"><a class=\"anchor\" href=\"#严格选举\">#</a> 严格选举</h4>\n<p>Raft 保证新选举出来的 leader 必须拥有之前 term 所有的 committed entries，也就是说 log entries 只能通过 leader 流向 follower 而不能从 follower 流向 leader。</p>\n<p>这里 candidate 赢得选举的条件有所不同。</p>\n<p>candidate 在请求投票时，会发送自己的 last log entry 和 follower 的 last log entry 进行对比。如果 candidate last log 的 term 要大，获得 term 相同时 candidate log entry 的 index 要大，则认为 candidate 是优先的，这时候才能进行投票。</p>\n<h4 id=\"committed规则\"><a class=\"anchor\" href=\"#committed规则\">#</a> committed 规则</h4>\n<p>论文的 figure 8 给出了这样一个情况：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220228215916592.png\" alt=\"image-20220228215916592\" /></p>\n<p>在 <code>c</code>  情况下， <code>s1</code>  作为 leader 将 index 2 复制给了 s2、s3。然后问题来了，这样 index 2 就是一个 committed entry 了，但是如果 s1 这时候挂掉，s5 参与到选举，由于 s5 在 term3 时候赢得了选举，所以他有 term3 的 log entry，那么 s5 在 <code>d</code>  情况可以赢得 term5 选举，并把 index 2 复制给了其他 server。可以看到此时的 index 2 的 term 变成了 3。之前的 committed 被覆盖了！</p>\n<p>于是 raft 规定，只有当前 term 的 log entries 才能通过计算 replicas 数的方式进行 <code>committed</code> 。</p>\n<p>这里又会有新的问题出现了！如果一个 command 对应了 log entries 是之前的 term，那么及时当前 leader 收到了 majority 的 confirm，那么 leader 也不能 apply 这个 log entry。一直到当前的 term 下来了 new command。那么这个旧 term 下的 log entry 才会得到 confirm。</p>\n<h4 id=\"safety-argument\"><a class=\"anchor\" href=\"#safety-argument\">#</a> Safety argument</h4>\n<p><strong>针对 figure 9 的情况</strong></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220228224051518.png\" alt=\"image-20220228224051518\" /></p>\n<p>我对于这张图的理解</p>\n<p>如果 s5 可以获得大部分选票的话，那么至少会出现 s3 这种既收到了之前 leader 的 log entry。请注意，论文描述严格选举有一个前提，那就是：赢得选举的 server 必须要在 majority 中保证 up-to-date log entry。这意味着 leader 如果自己任期内的 committed entry 一直是 up-to-date。也就是说 s5 不可能通过选举！</p>\n<p>有一说一，还是有的抽象。。。。</p>\n<h4 id=\"timing-and-availability\"><a class=\"anchor\" href=\"#timing-and-availability\">#</a> Timing and availability</h4>\n<p>需要保证</p>\n<p><strong>broadcastTime≪electionTimeout≪MTBF</strong></p>\n<p><code>broadcastTime</code>  就是平行发送 RPCs 的平均发送时间 + 接受响应时间。</p>\n<p><code>electionTimeout</code> ：这个就是之前提到了选举超时。</p>\n<p><code>MTBF</code>  ：the average time between failures for a single server</p>\n<p><strong>MTBFs are several months or more</strong>，所以这个不等式很容易满足</p>\n<h3 id=\"log-compaction\"><a class=\"anchor\" href=\"#log-compaction\">#</a> Log compaction</h3>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220301092739411.png\" alt=\"image-20220301092739411\" /></p>\n<p>raft 的 snap 机制用于压缩日志，其实它也很简单。</p>\n<p><code>last included index</code>  就是 the last entry the state machine had applied，就是 last apply index，注意，只有 committed 的 entry 才会被 apply，而 raft 可以确保所有 committed entry 都会在 state machine 得到 apply。</p>\n<p>** 并且这个 snapshot 还包含 state machine state！** 这是创建 snap 的最大开销。</p>\n<p>所以之前已经 apply 的 log entry 实际上已经没啥太大帮助了，我们只需要保存 last 用于 AppendEntries consistency check。</p>\n<p>对于特殊情况，比如 leader 现在需要废弃 log entries，但是这些 log entries 中还有一些没有发送给某个 follower，比如 follower server 执行很慢，这个 server 刚刚加入网络。。。</p>\n<p>于是这是 leader 会调用 InstallSnapShot RPC：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220301095816047.png\" alt=\"image-20220301095816047\" /></p>\n<p>leader 通过发送 chunk 方式，把 snapshot 发送给 follower。</p>\n<p>如果 follower 的 last log entry 比接收到的 snapshot 里的 last index 还要 stale，那么 follower 就把全部 log entrie 给扔了。如果 follower pre index 和 snap 里的 last index 重合，那么就只丢弃之前的。</p>\n<p>snapshot 的创建规则：</p>\n<ol>\n<li>固定 log size 触发创建 snapshot。</li>\n<li>copy-on-write 技术用于创建。</li>\n</ol>\n<h3 id=\"听讲\"><a class=\"anchor\" href=\"#听讲\">#</a> 听讲</h3>\n<p>使用 condition</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226202117673.png\" alt=\"image-20220226202117673\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226202457559.png\" alt=\"image-20220226202457559\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226210149391.png\" alt=\"image-20220226210149391\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220226210527368.png\" alt=\"image-20220226210527368\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220227155319505.png\" alt=\"image-20220227155319505\" /></p>\n<p>这张图很好地解答了我的疑惑，raft 中的 server 只能是 leader 来对外提供服务，从 client 发送请求到 leader 响应过程分为：</p>\n<ul>\n<li>client 向 server 发送请求，发送给 follower 的请求会被 follower 转发给 leader。</li>\n<li>leader 把 client command 写在 log 中，并通过 Append Entites RPC 发送给其他 followers。</li>\n<li>followers 返回确认消息，如果集群中 majority 都响应了，也就是说 leader 知道了 cluster 中大部分节点就收到了这些 log entity，那么对应的 entity 就是 <code>committed</code> 。</li>\n<li>leader 确认 entity 是 committed 之后，就会开始执行 entity 对应的 command，并把执行这个 command 再次发送给 followers。</li>\n<li>followers 收到确认执行 request 之后开始执行。</li>\n</ul>\n<p>我之前想到的 split partition 问题就可以很好解决了，如果集群分裂为两个 partition，然后各自都有 leader，那么对于 min partition 来说，leader 收不到 majority 的确认，因此 leader 没法执行指令。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220301110023351.png\" alt=\"image-20220301110023351\" /></p>\n<p>raft 使用 fast backup 方法。</p>\n<h3 id=\"线性一致性\"><a class=\"anchor\" href=\"#线性一致性\">#</a> 线性一致性</h3>\n<h4 id=\"什么是线性一致性\"><a class=\"anchor\" href=\"#什么是线性一致性\">#</a> <strong>什么是线性一致性？</strong></h4>\n<p>Raft 里提到的线性一致性：</p>\n<p><strong>Linearizable semantics</strong> （Linearizability）(each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response)</p>\n<ul>\n<li>\n<p>在一个线性一致性的系统里面，任何操作都可能在调用或者返回之间原子和瞬间执行</p>\n</li>\n<li>\n<p>线性一致性，Linearizability，也称为原子一致性（atomic consistency），强一致性（strong consistency）等</p>\n</li>\n<li>\n<p>也就是通常所说的 CAP 理论中的 C</p>\n</li>\n</ul>\n<p>实现线性一致性需要满足三点：</p>\n<ul>\n<li>瞬间完成（原子性）</li>\n<li>发生在 Inv 和 Resp 两个事件之间</li>\n<li>反映出 “最新” 的值</li>\n</ul>\n<p>1 和 2 很好理解，但 “最新” 怎么理解呢？其实很简单就看写操作：<br />\n<img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220301144626139.png\" alt=\"image-20220301144626139\" /></p>\n<p>在图中，x 的值被写操作划分为 3 个区域，每个区域内对应最新的值，也就是说 “最新” 并不代表<strong>确定</strong>！</p>\n<h4 id=\"教授讲的线性一致性\"><a class=\"anchor\" href=\"#教授讲的线性一致性\">#</a> 教授讲的线性一致性</h4>\n<p>我觉得教授讲的更加言简意赅：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220316100700951.png\" alt=\"image-20220316100700951\" /></p>\n<p>如果执行历史是线性的，那么存在操作序列，满足<strong>执行顺序和真实时间相匹配</strong>，<strong>每个读操作一定看到了最新写操作结果</strong>。</p>\n<p>我们以下面这张图为例子：</p>\n<p><strong>执行顺序和真实时间相匹配</strong>：对于非并发也就是时间上不重合的请求，比如 w1 和 w2。这两个请求在时间上不重合所以一定是 w2 发生在 w1 之前。但是对于并发也就是时间上有重合的请求，则需要  <code>each operation appears to execute instantaneously</code> 。</p>\n<p><strong>每个读操作一定看到了最新写操作结果</strong>：这句话的意思就是 R 一定发生在 W 之后，比如读 R1 一定发生在 W1 之后，假如没有最新的 W 操作，那么之后所有读操作一定都是返回 1 的。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturespicturespicturesimage-20220301122149285.png\" alt=\"image-20220301122149285\" /></p>\n<h3 id=\"遇到的问题\"><a class=\"anchor\" href=\"#遇到的问题\">#</a> 遇到的问题</h3>\n<h4 id=\"227日更新\"><a class=\"anchor\" href=\"#227日更新\">#</a> 2.27 日更新：</h4>\n<p>成功完成了 Lab2A，但是还遗留了一个问题，那就是为什么限制选举执行时间才能通过 test，按道理只要选举超时之后，之前选举的结果就会被废弃的。。。</p>\n<pre><code>Test (2A): initial election ...\nlabgob warning: Decoding into a non-default variable/field Term may not work\n  ... Passed --   3.0  3   56    6872    0\nTest (2A): election after network failure ...\n  ... Passed --   9.2  3  238   17813    0\nTest (2A): multiple elections ...\n  ... Passed --   6.5  7  642   55493    0\nPASS\nok  \t6.824/raft\t18.733s\n\n</code></pre>\n<h4 id=\"31号更新\"><a class=\"anchor\" href=\"#31号更新\">#</a> 3.1 号更新</h4>\n<p>raft 在 leader 当选之后会立即在 leader 的 log 中生成一条 no-hup 日志并通过 heartbeat 传递给其他 server。但是在 MIT6.824 实验中没办法实现 no-hup。</p>\n<h4 id=\"34-更新\"><a class=\"anchor\" href=\"#34-更新\">#</a> 3.4 更新</h4>\n<p>愉快通关！</p>\n",
            "tags": [
                "分布式",
                "MIT6.824"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/Artur-%E8%B0%83%E5%BA%A6%E5%99%A8/",
            "url": "https://songlinlife.top/2022/Artur-%E8%B0%83%E5%BA%A6%E5%99%A8/",
            "title": "Artur: 调度器",
            "date_published": "2022-02-25T13:46:15.000Z",
            "content_html": "<p>这玩意有点像我之前写过的 MapReduce，也是单 master 负责调度，多 worker 负责执行 task。并且一个 worker 只允许执行一个任务，但执行完任务后可以重新申请 task。</p>\n<p>Artur 就是负责之前 <code>perceval</code>  任务的调度，分为 <code>arthurd</code>  和  <code>arthurw</code> 。 <code>arthurd</code>  也就是服务端，负责 assign task。而  <code>arturw</code>  负责申请 task 然后执行。</p>\n<h3 id=\"配置文件\"><a class=\"anchor\" href=\"#配置文件\">#</a> 配置文件</h3>\n<p><code>Arturd</code> ：</p>\n<figure class=\"highlight ini\"><figcaption data-lang=\"ini\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token header\"><span class=\"token punctuation\">[</span><span class=\"token section-name selector\">arthur</span><span class=\"token punctuation\">]</span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token key attr-name\">archive_path</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">/tmp/.arthur/archive</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token key attr-name\">debug</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">True</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token key attr-name\">log_path</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">/tmp/logs/arthurd</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token key attr-name\">no_archive</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">True</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token key attr-name\">sync_mode</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">True</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token header\"><span class=\"token punctuation\">[</span><span class=\"token section-name selector\">connection</span><span class=\"token punctuation\">]</span></span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token key attr-name\">host</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">127.0.0.1</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token key attr-name\">port</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">8080</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token header\"><span class=\"token punctuation\">[</span><span class=\"token section-name selector\">elasticsearch</span><span class=\"token punctuation\">]</span></span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token key attr-name\">es_index</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">http://localhost:9200/items</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token header\"><span class=\"token punctuation\">[</span><span class=\"token section-name selector\">redis</span><span class=\"token punctuation\">]</span></span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token key attr-name\">database</span><span class=\"token punctuation\">=</span><span class=\"token value attr-value\">redis://localhost/8</span></pre></td></tr></table></figure><p>可以指定 port，用于提供服务。</p>\n<p><code>Arturw</code> ：</p>\n<pre><code class=\"language-sh\">arthurw -d redis://localhost/8\n</code></pre>\n<p>直接给 redis 数据库地址。</p>\n<h3 id=\"添加task\"><a class=\"anchor\" href=\"#添加task\">#</a> 添加 task</h3>\n<pre><code class=\"language-sh\">$ cat tasks.json\n&#123;\n    &quot;tasks&quot;: [\n        &#123;\n            &quot;task_id&quot;: &quot;arthur.git&quot;,\n            &quot;backend&quot;: &quot;git&quot;,\n            &quot;backend_args&quot;: &#123;\n                &quot;gitpath&quot;: &quot;/tmp/git/arthur.git/&quot;,\n                &quot;uri&quot;: &quot;https://github.com/chaoss/grimoirelab-kingarthur.git&quot;,\n                &quot;from_date&quot;: &quot;2015-03-01&quot;\n            &#125;,\n            &quot;category&quot;: &quot;commit&quot;,\n            &quot;scheduler&quot;: &#123;\n                &quot;delay&quot;: 10\n            &#125;\n        &#125;,\n        &#123;\n            &quot;task_id&quot;: &quot;bugzilla_mozilla&quot;,\n            &quot;backend&quot;: &quot;bugzillarest&quot;,\n            &quot;backend_args&quot;: &#123;\n                &quot;url&quot;: &quot;https://bugzilla.mozilla.org/&quot;,\n                &quot;from_date&quot;: &quot;2016-09-19&quot;\n            &#125;,\n            &quot;category&quot;: &quot;bug&quot;,\n            &quot;archive&quot;: &#123;\n                &quot;fetch_from_archive&quot;: true,\n                &quot;archived_after&quot;: &quot;2018-02-26 09:00&quot;\n            &#125;,\n            &quot;scheduler&quot;: &#123;\n                &quot;delay&quot;: 60,\n                &quot;max_retries&quot;: 5\n            &#125;\n        &#125;\n    ]\n&#125;\n</code></pre>\n<p>然后发送：</p>\n<pre><code class=\"language-sh\">curl -H &quot;Content-Type: application/json&quot; --data @tasks.json http://127.0.0.1:8080/add\n</code></pre>\n<p>可以这很 restful。</p>\n<h3 id=\"后续\"><a class=\"anchor\" href=\"#后续\">#</a> 后续</h3>\n<p>本来想自己运行一下的，但是呃呃我的 redis 镜像一直拉不下来，就懒得弄了。</p>\n",
            "tags": [
                "xlab"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/Graal-%E5%AD%98%E5%82%A8%E5%BA%93%E5%88%86%E6%9E%90%E5%99%A8/",
            "url": "https://songlinlife.top/2022/Graal-%E5%AD%98%E5%82%A8%E5%BA%93%E5%88%86%E6%9E%90%E5%99%A8/",
            "title": "Graal: 存储库分析器",
            "date_published": "2022-02-25T12:08:11.000Z",
            "content_html": "<p>Graal leverages on the Git backend of <span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2NoYW9zcy9ncmltb2lyZWxhYi1wZXJjZXZhbA==\">Perceval</span> and enhances it to set up ad-hoc source code analysis. Thus, it fetches the commits from a Git repository and provides a mechanism to plug third party tools/libraries focused on source code analysis.</p>\n<p>Graal 就是使用了之前提到的 perceval 组件的 git backend。拉取 repo 的 commits 并且提供一种方法使用第三方工具用于源码分析。</p>\n<h2 id=\"how-it-works\"><a class=\"anchor\" href=\"#how-it-works\">#</a> How it works</h2>\n<p>就是拉取一个 git repo 镜像以及 commits 的 meta data。通过创建工作树来执行 checkout 操作。Graal 获取 json 后，分为三步：</p>\n<ul>\n<li>Filter。通过 json 文档，选择或者丢弃 commit。然后在工作树上用 commit hash 来执行 checkout 操作。</li>\n<li>Analyze。就是引入分析工具。</li>\n<li>Post-process。最后一步处理 json 文档，比如删除或者重命名。</li>\n</ul>\n<h3 id=\"安装教程\"><a class=\"anchor\" href=\"#安装教程\">#</a> 安装教程</h3>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2NoYW9zcy9ncmltb2lyZWxhYi1ncmFhbA==\">https://github.com/chaoss/grimoirelab-graal</span></p>\n<h3 id=\"常见后端\"><a class=\"anchor\" href=\"#常见后端\">#</a> 常见后端</h3>\n<p><strong>CoCom</strong>: 代码复杂度分析。</p>\n<p><strong>CoDep</strong>：解析 python 模块的依赖并且转换为 json 格式，而且还可以使用 graph 可视化。</p>\n<p><strong>CoQua</strong>：检查代码的质量。</p>\n<p><strong>CoVuln</strong>：检查代码的安全性比如将在的 sql 注入、shell 注入。</p>\n<p><strong>CoLic</strong> ：扫描代码并且提取 licens 和版权信息。</p>\n<p><strong>CoLang</strong> ：获得 git repo 的代码语言分布洞察。</p>\n<h3 id=\"用法\"><a class=\"anchor\" href=\"#用法\">#</a> 用法</h3>\n<p>和 <code>perceval</code>  相类似：</p>\n<pre><code class=\"language-sh\">$ graal cocom https://github.com/chaoss/grimoirelab-perceval --git-path /tmp/graal-cocom &gt; /graal-cocom.test\nStarting the quest for the Graal.\nGit worktree /tmp/... created!\nFetching commits: ...\nGit worktree /tmp/... deleted!\nFetch process completed: .. commits inspected\nQuest completed.\n</code></pre>\n<h4 id=\"python中\"><a class=\"anchor\" href=\"#python中\">#</a> python 中：</h4>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#! /usr/bin/env python3</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> graal<span class=\"token punctuation\">.</span>backends<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>cocom <span class=\"token keyword\">import</span> CoCom</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># URL for the git repo to analyze</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>repo_uri <span class=\"token operator\">=</span> ’http<span class=\"token punctuation\">:</span><span class=\"token operator\">//</span>github<span class=\"token punctuation\">.</span>com<span class=\"token operator\">/</span>chaoss<span class=\"token operator\">/</span>grimoirelab<span class=\"token operator\">-</span>perceval’</pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># directory where to mirror the repo</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>repo_dir <span class=\"token operator\">=</span> ’<span class=\"token operator\">/</span>tmp<span class=\"token operator\">/</span>graal<span class=\"token operator\">-</span>cocom’</pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># Cocom object initialization</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>cc <span class=\"token operator\">=</span> CoCom<span class=\"token punctuation\">(</span>uri<span class=\"token operator\">=</span>repo_uri<span class=\"token punctuation\">,</span> git_path<span class=\"token operator\">=</span>repo_dir<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># fetch all commits</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>commits <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>commit <span class=\"token keyword\">for</span> commit <span class=\"token keyword\">in</span> cc<span class=\"token punctuation\">.</span>fetch<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure>",
            "tags": [
                "xlab"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-The-Design-of-a-Practical-System-for-Fault-Tolerant-Virtual-Machines/",
            "url": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-The-Design-of-a-Practical-System-for-Fault-Tolerant-Virtual-Machines/",
            "title": "MIT6.824: The Design of a Practical System for Fault-Tolerant Virtual Machines",
            "date_published": "2022-02-25T02:18:21.000Z",
            "content_html": "<h3 id=\"错误容忍\"><a class=\"anchor\" href=\"#错误容忍\">#</a> 错误容忍</h3>\n<h3 id=\"论文\"><a class=\"anchor\" href=\"#论文\">#</a> 论文</h3>\n<h4 id=\"primarybackup\"><a class=\"anchor\" href=\"#primarybackup\">#</a> primary/backup</h4>\n<p>这篇 paper 提出了一种 VM 错误容忍的方法，简单来说就是设置 Primary/backup。primary 用于提供服务，而 backup 用于做 primary 的备份。如果 primary 挂掉之后，那么 backup 能够自动地接管服务，给外界 client 一种没有发生过故障的错觉。</p>\n<p>该方法的核心思想就是保证 primary 和 backup 状态相同，方法也很简单。primary 执行什么操作，backup 也执行什么操作。如果有一个不确定的信息，那么这些信息会被 primary 传送给 backup。这样保证若 backup 和 primary 一直状态相同。</p>\n<p>The Design of a Practical System for Fault-Tolerant</p>\n<h4 id=\"基本设计\"><a class=\"anchor\" href=\"#基本设计\">#</a> 基本设计</h4>\n<p>首先是 shared disk 架构，如图所示：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220225110519498.png\" alt=\"image-20220225110519498\" /></p>\n<p>只有 primary 会被暴露在网络中，所以 client 的输入都会输出给 primary。primary 的所有输出都通过 logging channel 给传送给 backup。</p>\n<p>确定操作的三个要求：</p>\n<ul>\n<li>primary 必须捕获确定的和非确定的信息。</li>\n<li>确地将输入和不确定信息应用到 backup</li>\n<li>不能降低性能</li>\n</ul>\n<h4 id=\"ft协议\"><a class=\"anchor\" href=\"#ft协议\">#</a> FT 协议</h4>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220225113932596.png\" alt=\"image-20220225113932596\" /></p>\n<p>primary 将 output operation 传递给 backup，并推迟 output，知道 backup 返回确认。但是这也有一个问题，如果 primary 发送 output operation 后立即挂了，那么 output 也会被发送 2 次。但是 tcp 协议可以处理这些重复包。</p>\n",
            "tags": [
                "分布式",
                "MIT6.824"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/xlab/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E7%BB%84%E4%BB%B6%E2%80%94%E2%80%94Perceval/",
            "url": "https://songlinlife.top/2022/xlab/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E7%BB%84%E4%BB%B6%E2%80%94%E2%80%94Perceval/",
            "title": "数据采集组件——Perceval",
            "date_published": "2022-02-24T13:54:45.000Z",
            "content_html": "<h1 id=\"数据采集组件perceval\"><a class=\"anchor\" href=\"#数据采集组件perceval\">#</a> 数据采集组件 ——Perceval</h1>\n<h3 id=\"官方文档\"><a class=\"anchor\" href=\"#官方文档\">#</a> 官方文档</h3>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9wZXJjZXZhbC5yZWFkdGhlZG9jcy5pby9lbi9sYXRlc3Qv\">https://perceval.readthedocs.io/en/latest/</span></p>\n<h3 id=\"介绍\"><a class=\"anchor\" href=\"#介绍\">#</a> 介绍</h3>\n<blockquote>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2NoYW9zcy9ncmltb2lyZWxhYi1wZXJjZXZhbA==\">Perceval</span> is a Python module for retrieving data from repositories related to software development. It works with many data sources, from git repositories and GitHub projects to mailing lists, Gerrit or StackOverflow, In this chapter, you will learn the basics of working with Perceval, including how to use it to retrieve information from some kinds of repositories. You’re on your way to software development analysis!</p>\n</blockquote>\n<p><code>perceval</code>  就是 <code>grimoirelab</code>  的数据源采集组件，也就是最基础的组件。</p>\n<h3 id=\"安装\"><a class=\"anchor\" href=\"#安装\">#</a> 安装</h3>\n<pre><code class=\"language-sh\">pip3 install perceval\n</code></pre>\n<p>或者也可以用 docker 方式：</p>\n<pre><code class=\"language-sh\">docker run -it grimoirelab/perceval\n</code></pre>\n<h3 id=\"食用方式\"><a class=\"anchor\" href=\"#食用方式\">#</a> 食用方式</h3>\n<p>这个工具说白了就是采集工具，它支持的后端有：</p>\n<pre><code>    askbot           Fetch questions and answers from Askbot site\n    bugzilla         Fetch bugs from a Bugzilla server\n    bugzillarest     Fetch bugs from a Bugzilla server (&gt;=5.0) using its REST API\n    confluence       Fetch contents from a Confluence server\n    discourse        Fetch posts from Discourse site\n    dockerhub        Fetch repository data from Docker Hub site\n    gerrit           Fetch reviews from a Gerrit server\n    git              Fetch commits from Git\n    github           Fetch issues, pull requests and repository information from GitHub\n    gitlab           Fetch issues, merge requests from GitLab\n    gitter           Fetch messages from a Gitter room\n    googlehits       Fetch hits from Google API\n    groupsio         Fetch messages from Groups.io\n    hyperkitty       Fetch messages from a HyperKitty archiver\n    jenkins          Fetch builds from a Jenkins server\n    jira             Fetch issues from JIRA issue tracker\n    launchpad        Fetch issues from Launchpad issue tracker\n    mattermost       Fetch posts from a Mattermost server\n    mbox             Fetch messages from MBox files\n    mediawiki        Fetch pages and revisions from a MediaWiki site\n    meetup           Fetch events from a Meetup group\n    nntp             Fetch articles from a NNTP news group\n    pagure           Fetch issues from Pagure\n    phabricator      Fetch tasks from a Phabricator site\n    pipermail        Fetch messages from a Pipermail archiver\n    redmine          Fetch issues from a Redmine server\n    rocketchat       Fetch messages from a Rocket.Chat channel\n    rss              Fetch entries from a RSS feed server\n    slack            Fetch messages from a Slack channel\n    stackexchange    Fetch questions from StackExchange sites\n    supybot          Fetch messages from Supybot log files\n    telegram         Fetch messages from the Telegram server\n    twitter          Fetch tweets from the Twitter Search API\n</code></pre>\n<p>有点意外，我没有想到连 Twitter 都能支持。。。。</p>\n<h4 id=\"git\"><a class=\"anchor\" href=\"#git\">#</a> git</h4>\n<pre><code class=\"language-sh\">time perceval git https://github.com/grimoirelab/perceval.git \\\n  --git-path /tmp/perceval.git &gt; /tmp/perceval.test\n</code></pre>\n<p>这条命令会将拉取到的 git commit 数据保存到对应了文件，格式为 json。</p>\n<p>同时还支持 python 脚本的方式：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#! /usr/bin/env python3</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">from</span> perceval<span class=\"token punctuation\">.</span>backends<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>git <span class=\"token keyword\">import</span> Git</pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># url for the git repo to analyze</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>repo_url <span class=\"token operator\">=</span> <span class=\"token string\">'http://github.com/grimoirelab/perceval.git'</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># directory for letting Perceval clone the git repo</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>repo_dir <span class=\"token operator\">=</span> <span class=\"token string\">'/tmp/perceval.git'</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># create a Git object, pointing to repo_url, using repo_dir for cloning</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>repo <span class=\"token operator\">=</span> Git<span class=\"token punctuation\">(</span>uri<span class=\"token operator\">=</span>repo_url<span class=\"token punctuation\">,</span> gitpath<span class=\"token operator\">=</span>repo_dir<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token comment\"># fetch all commits as an iterator, and iterate it printing each hash</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token keyword\">for</span> commit <span class=\"token keyword\">in</span> repo<span class=\"token punctuation\">.</span>fetch<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>commit<span class=\"token punctuation\">[</span><span class=\"token string\">'data'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'commit'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h4 id=\"github\"><a class=\"anchor\" href=\"#github\">#</a> github</h4>\n<pre><code class=\"language-sh\"> perceval github grimoirelab perceval --sleep-for-rate \\\n    -t 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 &gt; ~/tmp/github.json\n</code></pre>\n<p>通过 perceval  backend repoOwner 这种方式来获取数据</p>\n<p>通过  <code>--category issue</code>  来指定获取 issue 信息，值得注意的是 github 会把 pr 当做 issue 进行处理，所以也会自动得到所有 pr 信息。</p>\n<pre><code class=\"language-获取数据格式\">&#123;\n    &quot;backend_name&quot;: &quot;GitHub&quot;,\n    &quot;backend_version&quot;: &quot;0.27.0&quot;,\n    &quot;category&quot;: &quot;issue&quot;,\n    &quot;classified_fields_filtered&quot;: null,\n    &quot;data&quot;: &#123;\n        &quot;active_lock_reason&quot;: null,\n        &quot;assignee&quot;: null,\n        &quot;assignee_data&quot;: &#123;&#125;,\n        &quot;assignees&quot;: [],\n        &quot;assignees_data&quot;: [],\n        &quot;author_association&quot;: &quot;CONTRIBUTOR&quot;,\n        &quot;body&quot;: &quot;Based on Sphynx, prepared for ReadTheDocs.\\n\\nRight now, this produces (from jgbarah/perceval repository) [this documentation in ReadTheDocs](http://perceval.readthedocs.org). Once this PR is accepted, I plan to switch ReadTheDocs to point to this repostory (master branch), so that the documentation gets rebuilt every time changes are made to the source code.\\n\\nThe configuration (docs/conf.py) include lines for running sphinx-apidoc, which generates automatically the docs/perceval.rst file, which is the entry point for the automatically generated documentation, produced based on the docstring comments in the source code.\\n\\nThe file index.rst is still a bare bones schema. It should be completed in a later patch, with more detailed information about Perceval itself.\\n&quot;,\n        &quot;closed_at&quot;: &quot;2016-01-04T13:51:56Z&quot;,\n        &quot;comments&quot;: 0,\n        &quot;comments_data&quot;: [],\n        &quot;comments_url&quot;: &quot;https://api.github.com/repos/chaoss/grimoirelab-perceval/issues/3/comments&quot;,\n        &quot;created_at&quot;: &quot;2016-01-03T23:46:04Z&quot;,\n        &quot;draft&quot;: false,\n        &quot;events_url&quot;: &quot;https://api.github.com/repos/chaoss/grimoirelab-perceval/issues/3/events&quot;,\n        &quot;html_url&quot;: &quot;https://github.com/chaoss/grimoirelab-perceval/pull/3&quot;,\n        &quot;id&quot;: 124679251,\n        &quot;labels&quot;: [],\n        &quot;labels_url&quot;: &quot;https://api.github.com/repos/chaoss/grimoirelab-perceval/issues/3/labels&#123;/name&#125;&quot;,\n        &quot;locked&quot;: false,\n        &quot;milestone&quot;: null,\n        &quot;node_id&quot;: &quot;MDExOlB1bGxSZXF1ZXN0NTQ5MzUxODA=&quot;,\n        &quot;number&quot;: 3,\n        &quot;performed_via_github_app&quot;: null,\n        &quot;pull_request&quot;: &#123;\n            &quot;diff_url&quot;: &quot;https://github.com/chaoss/grimoirelab-perceval/pull/3.diff&quot;,\n            &quot;html_url&quot;: &quot;https://github.com/chaoss/grimoirelab-perceval/pull/3&quot;,\n            &quot;merged_at&quot;: null,\n            &quot;patch_url&quot;: &quot;https://github.com/chaoss/grimoirelab-perceval/pull/3.patch&quot;,\n            &quot;url&quot;: &quot;https://api.github.com/repos/chaoss/grimoirelab-perceval/pulls/3&quot;\n        &#125;,\n        &quot;reactions&quot;: &#123;\n            &quot;+1&quot;: 0,\n            &quot;-1&quot;: 0,\n            &quot;confused&quot;: 0,\n            &quot;eyes&quot;: 0,\n            &quot;heart&quot;: 0,\n            &quot;hooray&quot;: 0,\n            &quot;laugh&quot;: 0,\n            &quot;rocket&quot;: 0,\n            &quot;total_count&quot;: 0,\n            &quot;url&quot;: &quot;https://api.github.com/repos/chaoss/grimoirelab-perceval/issues/3/reactions&quot;\n        &#125;,\n        &quot;reactions_data&quot;: [],\n        &quot;repository_url&quot;: &quot;https://api.github.com/repos/chaoss/grimoirelab-perceval&quot;,\n        &quot;state&quot;: &quot;closed&quot;,\n        &quot;timeline_url&quot;: &quot;https://api.github.com/repos/chaoss/grimoirelab-perceval/issues/3/timeline&quot;,\n        &quot;title&quot;: &quot;Config files for a documentation, using Sphinx.&quot;,\n        &quot;updated_at&quot;: &quot;2016-01-04T17:42:23Z&quot;,\n        &quot;url&quot;: &quot;https://api.github.com/repos/chaoss/grimoirelab-perceval/issues/3&quot;,\n        &quot;user&quot;: &#123;\n            &quot;avatar_url&quot;: &quot;https://avatars.githubusercontent.com/u/1039693?v=4&quot;,\n            &quot;events_url&quot;: &quot;https://api.github.com/users/jgbarah/events&#123;/privacy&#125;&quot;,\n            &quot;followers_url&quot;: &quot;https://api.github.com/users/jgbarah/followers&quot;,\n            &quot;following_url&quot;: &quot;https://api.github.com/users/jgbarah/following&#123;/other_user&#125;&quot;,\n            &quot;gists_url&quot;: &quot;https://api.github.com/users/jgbarah/gists&#123;/gist_id&#125;&quot;,\n            &quot;gravatar_id&quot;: &quot;&quot;,\n            &quot;html_url&quot;: &quot;https://github.com/jgbarah&quot;,\n            &quot;id&quot;: 1039693,\n            &quot;login&quot;: &quot;jgbarah&quot;,\n            &quot;node_id&quot;: &quot;MDQ6VXNlcjEwMzk2OTM=&quot;,\n            &quot;organizations_url&quot;: &quot;https://api.github.com/users/jgbarah/orgs&quot;,\n            &quot;received_events_url&quot;: &quot;https://api.github.com/users/jgbarah/received_events&quot;,\n            &quot;repos_url&quot;: &quot;https://api.github.com/users/jgbarah/repos&quot;,\n            &quot;site_admin&quot;: false,\n            &quot;starred_url&quot;: &quot;https://api.github.com/users/jgbarah/starred&#123;/owner&#125;&#123;/repo&#125;&quot;,\n            &quot;subscriptions_url&quot;: &quot;https://api.github.com/users/jgbarah/subscriptions&quot;,\n            &quot;type&quot;: &quot;User&quot;,\n            &quot;url&quot;: &quot;https://api.github.com/users/jgbarah&quot;\n        &#125;,\n        &quot;user_data&quot;: &#123;\n            &quot;avatar_url&quot;: &quot;https://avatars.githubusercontent.com/u/1039693?v=4&quot;,\n            &quot;bio&quot;: null,\n            &quot;blog&quot;: &quot;http://gsyc.es/~jgb&quot;,\n            &quot;company&quot;: null,\n            &quot;created_at&quot;: &quot;2011-09-09T21:47:40Z&quot;,\n            &quot;email&quot;: null,\n            &quot;events_url&quot;: &quot;https://api.github.com/users/jgbarah/events&#123;/privacy&#125;&quot;,\n            &quot;followers&quot;: 100,\n            &quot;followers_url&quot;: &quot;https://api.github.com/users/jgbarah/followers&quot;,\n            &quot;following&quot;: 0,\n            &quot;following_url&quot;: &quot;https://api.github.com/users/jgbarah/following&#123;/other_user&#125;&quot;,\n            &quot;gists_url&quot;: &quot;https://api.github.com/users/jgbarah/gists&#123;/gist_id&#125;&quot;,\n            &quot;gravatar_id&quot;: &quot;&quot;,\n            &quot;hireable&quot;: null,\n            &quot;html_url&quot;: &quot;https://github.com/jgbarah&quot;,\n            &quot;id&quot;: 1039693,\n            &quot;location&quot;: null,\n            &quot;login&quot;: &quot;jgbarah&quot;,\n            &quot;name&quot;: &quot;Jesus M. Gonzalez-Barahona&quot;,\n            &quot;node_id&quot;: &quot;MDQ6VXNlcjEwMzk2OTM=&quot;,\n            &quot;organizations&quot;: [\n                &#123;\n                    &quot;avatar_url&quot;: &quot;https://avatars.githubusercontent.com/u/1843608?v=4&quot;,\n                    &quot;description&quot;: null,\n                    &quot;events_url&quot;: &quot;https://api.github.com/orgs/MetricsGrimoire/events&quot;,\n                    &quot;hooks_url&quot;: &quot;https://api.github.com/orgs/MetricsGrimoire/hooks&quot;,\n                    &quot;id&quot;: 1843608,\n                    &quot;issues_url&quot;: &quot;https://api.github.com/orgs/MetricsGrimoire/issues&quot;,\n                    &quot;login&quot;: &quot;MetricsGrimoire&quot;,\n                    &quot;members_url&quot;: &quot;https://api.github.com/orgs/MetricsGrimoire/members&#123;/member&#125;&quot;,\n                    &quot;node_id&quot;: &quot;MDEyOk9yZ2FuaXphdGlvbjE4NDM2MDg=&quot;,\n                    &quot;public_members_url&quot;: &quot;https://api.github.com/orgs/MetricsGrimoire/public_members&#123;/member&#125;&quot;,\n                    &quot;repos_url&quot;: &quot;https://api.github.com/orgs/MetricsGrimoire/repos&quot;,\n                    &quot;url&quot;: &quot;https://api.github.com/orgs/MetricsGrimoire&quot;\n                &#125;,\n                &#123;\n                    &quot;avatar_url&quot;: &quot;https://avatars.githubusercontent.com/u/1918070?v=4&quot;,\n                    &quot;description&quot;: null,\n                    &quot;events_url&quot;: &quot;https://api.github.com/orgs/Bitergia/events&quot;,\n                    &quot;hooks_url&quot;: &quot;https://api.github.com/orgs/Bitergia/hooks&quot;,\n                    &quot;id&quot;: 1918070,\n                    &quot;issues_url&quot;: &quot;https://api.github.com/orgs/Bitergia/issues&quot;,\n                    &quot;login&quot;: &quot;Bitergia&quot;,\n                    &quot;members_url&quot;: &quot;https://api.github.com/orgs/Bitergia/members&#123;/member&#125;&quot;,\n                    &quot;node_id&quot;: &quot;MDEyOk9yZ2FuaXphdGlvbjE5MTgwNzA=&quot;,\n                    &quot;public_members_url&quot;: &quot;https://api.github.com/orgs/Bitergia/public_members&#123;/member&#125;&quot;,\n                    &quot;repos_url&quot;: &quot;https://api.github.com/orgs/Bitergia/repos&quot;,\n                    &quot;url&quot;: &quot;https://api.github.com/orgs/Bitergia&quot;\n                &#125;,\n                &#123;\n                    &quot;avatar_url&quot;: &quot;https://avatars.githubusercontent.com/u/2191340?v=4&quot;,\n                    &quot;description&quot;: null,\n                    &quot;events_url&quot;: &quot;https://api.github.com/orgs/VizGrimoire/events&quot;,\n                    &quot;hooks_url&quot;: &quot;https://api.github.com/orgs/VizGrimoire/hooks&quot;,\n                    &quot;id&quot;: 2191340,\n                    &quot;issues_url&quot;: &quot;https://api.github.com/orgs/VizGrimoire/issues&quot;,\n                    &quot;login&quot;: &quot;VizGrimoire&quot;,\n                    &quot;members_url&quot;: &quot;https://api.github.com/orgs/VizGrimoire/members&#123;/member&#125;&quot;,\n                    &quot;node_id&quot;: &quot;MDEyOk9yZ2FuaXphdGlvbjIxOTEzNDA=&quot;,\n                    &quot;public_members_url&quot;: &quot;https://api.github.com/orgs/VizGrimoire/public_members&#123;/member&#125;&quot;,\n                    &quot;repos_url&quot;: &quot;https://api.github.com/orgs/VizGrimoire/repos&quot;,\n                    &quot;url&quot;: &quot;https://api.github.com/orgs/VizGrimoire&quot;\n                &#125;,\n                &#123;\n                    &quot;avatar_url&quot;: &quot;https://avatars.githubusercontent.com/u/3017044?v=4&quot;,\n                    &quot;description&quot;: null,\n                    &quot;events_url&quot;: &quot;https://api.github.com/orgs/AlertProject/events&quot;,\n                    &quot;hooks_url&quot;: &quot;https://api.github.com/orgs/AlertProject/hooks&quot;,\n                    &quot;id&quot;: 3017044,\n                    &quot;issues_url&quot;: &quot;https://api.github.com/orgs/AlertProject/issues&quot;,\n                    &quot;login&quot;: &quot;AlertProject&quot;,\n                    &quot;members_url&quot;: &quot;https://api.github.com/orgs/AlertProject/members&#123;/member&#125;&quot;,\n                    &quot;node_id&quot;: &quot;MDEyOk9yZ2FuaXphdGlvbjMwMTcwNDQ=&quot;,\n                    &quot;public_members_url&quot;: &quot;https://api.github.com/orgs/AlertProject/public_members&#123;/member&#125;&quot;,\n                    &quot;repos_url&quot;: &quot;https://api.github.com/orgs/AlertProject/repos&quot;,\n                    &quot;url&quot;: &quot;https://api.github.com/orgs/AlertProject&quot;\n                &#125;,\n                &#123;\n                    &quot;avatar_url&quot;: &quot;https://avatars.githubusercontent.com/u/16151805?v=4&quot;,\n                    &quot;description&quot;: &quot;&quot;,\n                    &quot;events_url&quot;: &quot;https://api.github.com/orgs/grimoirelab/events&quot;,\n                    &quot;hooks_url&quot;: &quot;https://api.github.com/orgs/grimoirelab/hooks&quot;,\n                    &quot;id&quot;: 16151805,\n                    &quot;issues_url&quot;: &quot;https://api.github.com/orgs/grimoirelab/issues&quot;,\n                    &quot;login&quot;: &quot;grimoirelab&quot;,\n                    &quot;members_url&quot;: &quot;https://api.github.com/orgs/grimoirelab/members&#123;/member&#125;&quot;,\n                    &quot;node_id&quot;: &quot;MDEyOk9yZ2FuaXphdGlvbjE2MTUxODA1&quot;,\n                    &quot;public_members_url&quot;: &quot;https://api.github.com/orgs/grimoirelab/public_members&#123;/member&#125;&quot;,\n                    &quot;repos_url&quot;: &quot;https://api.github.com/orgs/grimoirelab/repos&quot;,\n                    &quot;url&quot;: &quot;https://api.github.com/orgs/grimoirelab&quot;\n                &#125;\n            ],\n            &quot;organizations_url&quot;: &quot;https://api.github.com/users/jgbarah/orgs&quot;,\n            &quot;public_gists&quot;: 0,\n            &quot;public_repos&quot;: 41,\n            &quot;received_events_url&quot;: &quot;https://api.github.com/users/jgbarah/received_events&quot;,\n            &quot;repos_url&quot;: &quot;https://api.github.com/users/jgbarah/repos&quot;,\n            &quot;site_admin&quot;: false,\n            &quot;starred_url&quot;: &quot;https://api.github.com/users/jgbarah/starred&#123;/owner&#125;&#123;/repo&#125;&quot;,\n            &quot;subscriptions_url&quot;: &quot;https://api.github.com/users/jgbarah/subscriptions&quot;,\n            &quot;twitter_username&quot;: null,\n            &quot;type&quot;: &quot;User&quot;,\n            &quot;updated_at&quot;: &quot;2022-02-16T16:51:43Z&quot;,\n            &quot;url&quot;: &quot;https://api.github.com/users/jgbarah&quot;\n        &#125;\n    &#125;,\n    &quot;origin&quot;: &quot;https://github.com/grimoirelab/perceval&quot;,\n    &quot;perceval_version&quot;: &quot;0.17.16&quot;,\n    &quot;search_fields&quot;: &#123;\n        &quot;item_id&quot;: &quot;124679251&quot;,\n        &quot;owner&quot;: &quot;grimoirelab&quot;,\n        &quot;repo&quot;: &quot;perceval&quot;\n    &#125;,\n    &quot;tag&quot;: &quot;https://github.com/grimoirelab/perceval&quot;,\n    &quot;timestamp&quot;: 1645709133.739694,\n    &quot;updated_on&quot;: 1451929343.0,\n    &quot;uuid&quot;: &quot;c403532b196ed4020cc86d001feb091c009d3d26&quot;\n&#125;\n</code></pre>\n<h3 id=\"获取器的架构\"><a class=\"anchor\" href=\"#获取器的架构\">#</a> 获取器的架构</h3>\n<p>Client: interacts directly with the data source.</p>\n<p>Backend: orchestrates the fetching process by using the Client.</p>\n<p>CommandLine: defines the arguments to initialize and run the Backend from the command line.</p>\n",
            "tags": [
                "xlab"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-GFS/",
            "url": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-GFS/",
            "title": "MIT6.824: GFS",
            "date_published": "2022-02-23T02:56:45.000Z",
            "content_html": "<h3 id=\"gfsgoogle-file-system\"><a class=\"anchor\" href=\"#gfsgoogle-file-system\">#</a> GFS（Google File System）</h3>\n<blockquote>\n<p>In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.</p>\n</blockquote>\n<p>这篇文章介绍旨在<strong>支持分布式应用程序的文件系统接口扩展</strong>，讨论了我们设计的许多方面，并报告了从微基准测试和真实世界使用两方面的测量结果。</p>\n<h4 id=\"keywords\"><a class=\"anchor\" href=\"#keywords\">#</a> Keywords</h4>\n<p>Fault tolerance, scalability, data storage, clustered storage</p>\n<h4 id=\"introduction\"><a class=\"anchor\" href=\"#introduction\">#</a> Introduction</h4>\n<blockquote>\n<p>constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system.</p>\n</blockquote>\n<p>作者认为持续监控，错误检测，故障容忍，自动恢复是系统的关键所在。</p>\n<h4 id=\"设计理念\"><a class=\"anchor\" href=\"#设计理念\">#</a> 设计理念</h4>\n<ul>\n<li>系统由许多便宜的机器组成，所以经常会有 fail 情况，监控、检测、故障恢复是日常。</li>\n<li>系统会存储很多 GB 级别的大文件。</li>\n<li>读负载主要分为两种：大流式读和小的随机读。</li>\n<li>写负载通常是 append data。也就是说文件是被 append 而不是修改。因此一个文件一旦写完之后就很少被修改。</li>\n<li>系统实现了多客户端并发 append 同一个文件</li>\n<li>高稳定带宽比低延迟更重要。</li>\n</ul>\n<h4 id=\"架构\"><a class=\"anchor\" href=\"#架构\">#</a> 架构</h4>\n<p>一个 master 机（以及多个 master 机的 remote 副本），多个 chunkservers，以及多个 clients。</p>\n<p>每一个 chunk 有 64M，并且被一个 64bit 的 chunk handle 给唯一标识。chunkhandle 是 chunk 创建时由 master 机分配的，并且如果 client 要访问 chunk 并且持有 chunk handle。</p>\n<h4 id=\"读操作\"><a class=\"anchor\" href=\"#读操作\">#</a> 读操作</h4>\n<ol>\n<li>client 将 filename 和 byte offset 转成 chunk index。</li>\n<li>client 向 master 发送 request，包含 chunk index 和 filename</li>\n<li>master 返回 chunk handle 和副本的 location。</li>\n<li>client 使用 filename 和 chunk index 作为 key，将 master 返回的数据作为 value，缓存起来。这样 client 在一段时间内就可以不用再和 master 沟通了。</li>\n<li>client 访问距离它最近的 replicas。</li>\n</ol>\n<h4 id=\"metadata\"><a class=\"anchor\" href=\"#metadata\">#</a> MetaData</h4>\n<p>三种主要的 MetaData：the file and chunk namespaces, the mapping from files to chunks, and the locations of each chunk’s replicas。</p>\n<p>主要 MetaData 都是存放在 Master 机的内存中，但是 <code>namespace</code>  和 <code>mapping</code>  是会写到 local disk 的 log 中，并且在 remote 机中存放备份。但是 location 不会有持续存储。</p>\n<p>因为集群经常会有机器加入、宕机、重启等情况，所以持续化存储 location 不是一个好的选择，最好还是周期性询问 chunkservers。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220223133116965.png\" alt=\"image-20220223133116965\" /></p>\n<h4 id=\"consistent和defined\"><a class=\"anchor\" href=\"#consistent和defined\">#</a> consistent 和 defined</h4>\n<p>如果所有 client 看到相同的数据，就被认为是 consistent。</p>\n<p>如果文件数据改动后，file region 还是 consistent 的，并且所有 client 都会看到 mutation writes 的全部内容，那么就说明 region 是_defined_。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220225093959514.png\" alt=\"image-20220225093959514\" /></p>\n<p>对于 GFS 来说，write 和 append 虽然都是 mutation 但是他们还是有不同的。</p>\n<h4 id=\"write和append\"><a class=\"anchor\" href=\"#write和append\">#</a> Write 和 Append</h4>\n<p>说实话我读第一遍论文时候搞不懂为什么 write 操作是 undefined 但 consistent 而 Record Append 操作是 defined 但 inconsistent。其实这个不同点就是 GFS 设计的巧妙之处，write chunk 操作需要制定 offset，而 Append 操作则不用。</p>\n<p>教授关于 Append 操作的这个例子讲的很好：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220225095400456.png\" alt=\"image-20220225095400456\" /></p>\n<p>对于 append 操作，如果第一次 Append 操作失败之后，那么会重新发起 append 请求，也就是 primary 再写一遍然后让其他副本也写一遍，那么问题就来了，之前的 Append 操作中，有的 replicas 成功写入了 data，有的没有。失败的操作不会要求这些 replicas 删除之前 append 失败操作写的数据，而是重新再尾部进行 Append，并且要求同一个 Records 在所有的 replicas 中具有相同的 offset。那么很显然上述的三个 replicas 中数据是不一致的，但我们可以看到每一个 append 操作写的数据，数据不会被覆盖，那么他就是一个 defined 操作。</p>\n<p>对于 write 操作，因为所有 client 机并发写相同的 offset，那么及时失败后，有的 replicas 写了，有的没有，那么在下一次重新发起 Write 操作中，会写覆盖掉之前写的数据。因此 write 操作是一致的，并且因为写覆盖，我们没法知道到底是什么序列写的，所有是 undefined。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220225094811181.png\" alt=\"image-20220225094811181\" /></p>\n<h4 id=\"snapshot\"><a class=\"anchor\" href=\"#snapshot\">#</a> snapshot</h4>\n<p>说实话，我没看懂块引用。。。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220223150359437.png\" alt=\"image-20220223150359437\" /></p>\n<h3 id=\"上课\"><a class=\"anchor\" href=\"#上课\">#</a> 上课</h3>\n<p>consistency 会导致 low performance</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220223182829839.png\" alt=\"image-20220223182829839\" /></p>\n<p>不好的分布式系统：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220223184155101.png\" alt=\"image-20220223184155101\" /></p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220223185145057.png\" alt=\"image-20220223185145057\" /></p>\n",
            "tags": [
                "分布式",
                "MIT6.824"
            ]
        },
        {
            "id": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-mapreduce/",
            "url": "https://songlinlife.top/2022/%E5%88%86%E5%B8%83%E5%BC%8F/MIT6-824-mapreduce/",
            "title": "MIT6.824: mapreduce",
            "date_published": "2022-02-20T02:28:51.000Z",
            "content_html": "<h3 id=\"开新坑了\"><a class=\"anchor\" href=\"#开新坑了\">#</a> 开新坑了！</h3>\n<p>令人感叹，自己虽然开了很多个坑，但是能够完成的却很少，这次的 MIT6.824 是我确定学的一门课程，要想入门分布式绕不开的一门课，没办法，老老实实学一次，把所有的 lab 做完，这就是我的目标！</p>\n<h3 id=\"论文阅读\"><a class=\"anchor\" href=\"#论文阅读\">#</a> 论文阅读</h3>\n<p>因为这门课必须要看论文，所以就很痛苦。。。</p>\n<h4 id=\"问题\"><a class=\"anchor\" href=\"#问题\">#</a> 问题</h4>\n<p>原有的计算是很简单的，但是因为数据很大需要做成分布式系统，所以如何 <code>并行化计算</code> 、 <code>分发数据</code> 和 <code>处理故障</code> 等问题使得原本简单的计算变得晦涩难懂，需要大量复杂的代码来处理这些问题。</p>\n<h4 id=\"mapreduce函数\"><a class=\"anchor\" href=\"#mapreduce函数\">#</a> MapReduce 函数</h4>\n<figure class=\"highlight go\"><figcaption data-lang=\"go\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">map</span><span class=\"token punctuation\">(</span>String key<span class=\"token punctuation\">,</span> String value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token comment\">// key: document name</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token comment\">// value: document contents</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">for</span> each word w in value<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    \t<span class=\"token function\">EmitIntermediate</span><span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> <span class=\"token string\">\"1\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token function\">reduce</span><span class=\"token punctuation\">(</span>String key<span class=\"token punctuation\">,</span> Iterator values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token comment\">// key: a word</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token comment\">// values: a list of counts</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token builtin\">int</span> result <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token keyword\">for</span> each v in values<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    \tresult <span class=\"token operator\">+=</span> <span class=\"token function\">ParseInt</span><span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>\t<span class=\"token function\">Emit</span><span class=\"token punctuation\">(</span><span class=\"token function\">AsString</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>map 用于发射中间键值对，而 reduce 函数则负责对中间键值对中相同的 key 进行 aggregate 处理。</p>\n<h4 id=\"执行概述\"><a class=\"anchor\" href=\"#执行概述\">#</a> 执行概述</h4>\n<p>首先明确 map 机和 reduce 机组成了一个分布式系统，所以这里有一个 master 机用于 assign 任务。</p>\n<ol>\n<li>将 raw data 切分为 M 个 splits。每一个 split 大小可以由用户进行指定。</li>\n<li>master 机将 map 任务和 reduce 任务分别自拍给不同的 workers。</li>\n<li>map 机读取 input split，通过 <code>Map</code>  函数将 k/v 对进行输出。这些中间键值对缓存在 map 机的内存中。</li>\n<li>这些缓存的键值对会定期存本地磁盘，同时会被分区函数分为 R 个 regions。可以用 hash (key) mod R。local disk 的位置会被发送给 master 即，master 机来告诉 reduce 机存储位置。</li>\n<li>reduce 机被 master 机告知存储位置后，通过 rpc 远程调用来读取有 map 机制造的缓存 kv 中间对。当 reduce 机读取完了所有的数据后，会通过 sort 操作来将相同 key 进行 group。因为中间数据可以过大，以至于难以读入到内存中，因此 sort 操作是必须的。</li>\n<li>reduce 即使用 <code>Reduce</code>  函数来对这些数据进行处理，并将数据输出到最终的分区。</li>\n<li>当 mapreduce 操作执行完毕后，master 机负责唤醒用户程序，并把 MapReduce 调用输出返回给用户程序。</li>\n</ol>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220220115958846.png\" alt=\"image-20220220115958846\" /></p>\n<h4 id=\"使用例子\"><a class=\"anchor\" href=\"#使用例子\">#</a> 使用例子</h4>\n<p>计算 URL 的频率，这个就和 wordcount 函数相同。</p>\n<p>ReverseWeb-Link Graph: map 函数输出 &lt;target, source&gt;，target 是对应的 url，而 source 就是 target url 出现的网页 URL，而 reduce 负责将 source 进行 concat，输出 &lt; target, list (source)&gt;</p>\n<p>Inverted Index: 和上面的例子类似。</p>\n<h3 id=\"分布式系统的特性\"><a class=\"anchor\" href=\"#分布式系统的特性\">#</a> 分布式系统的特性</h3>\n<h4 id=\"错误容忍\"><a class=\"anchor\" href=\"#错误容忍\">#</a> 错误容忍</h4>\n<p>Availability：即使一些机器发生了故障，系统依旧可以提供无误的服务，注意，如果很多机器都宕机，available system 仍然会停止运行，但得到修复后，系统可以继续正确运行。</p>\n<p>Recoverability：系统发生故障后，经过修复仍然可以正确运行，因此 Availability 就包含了系统需要 Recoverability。</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220221152942785.png\" alt=\"image-20220221152942785\" /></p>\n<h3 id=\"lab1\"><a class=\"anchor\" href=\"#lab1\">#</a> LAB1</h3>\n<h4 id=\"job\"><a class=\"anchor\" href=\"#job\">#</a> Job</h4>\n<p>实现分布式 MapReduce，包含两个程序，master 和 worker。worker 和 master 之间通信通过 RPC，每个 worker process 将会向 master 询问任务，读取任务输入，执行任务，并将任务结果输出到一个或多个文件中。如果 worker 不不能在 10s 的时间内完成任务，master 需要将任务分配给另一个 worker。</p>\n<p>执行过程：</p>\n<p>生成插件</p>\n<figure class=\"highlight go\"><figcaption data-lang=\"go\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">go</span> build <span class=\"token operator\">-</span>buildmode<span class=\"token operator\">=</span>plugin <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>mrapps<span class=\"token operator\">/</span>wc<span class=\"token punctuation\">.</span><span class=\"token keyword\">go</span></pre></td></tr></table></figure><p>在 main 目录下执行：</p>\n<figure class=\"highlight go\"><figcaption data-lang=\"go\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">go</span> run mrmaster<span class=\"token punctuation\">.</span><span class=\"token keyword\">go</span> pg<span class=\"token operator\">-</span><span class=\"token operator\">*</span><span class=\"token punctuation\">.</span>txt</pre></td></tr></table></figure><p>这个就是 master 函数</p>\n<p>执行 worker</p>\n<figure class=\"highlight go\"><figcaption data-lang=\"go\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">go</span> run mrworker<span class=\"token punctuation\">.</span><span class=\"token keyword\">go</span> wc<span class=\"token punctuation\">.</span>so</pre></td></tr></table></figure><h4 id=\"需要遵守的规则\"><a class=\"anchor\" href=\"#需要遵守的规则\">#</a> 需要遵守的规则</h4>\n<ol>\n<li>map 函数传递的中间 key 需要分配到 nReduce 个 bucket 中，而 <code>NReduce</code>  这个参数会被 <code>main/mrmaster.go</code>  传递给 <code>MakeMaster()</code></li>\n<li>结果需要保持为 <code>mr-out-X</code>  这种格式，其中 <code>X</code>  是 <code>reduce</code>  的编号。</li>\n<li><code>mr-out-x</code>  文件中每一行记录了 reduce 的输出，并且格式为  <code>%v %v</code></li>\n<li>只能改动这三个文件 <code>mr/worker.go</code> ,  <code>mr/master.go</code> ,  <code>mr/rpc.go</code> 。</li>\n<li>worker 需要把 map 的中间结果保存到当前目录中。</li>\n<li>mr/master.go 中需要实现 <code>Done()</code>  方法，如果返回 <code>true</code>  表示 MapReduce 任务执行完成，  <code>mrmaster.go</code>  才会退出。</li>\n<li>worker 还需要实现 <code>call</code>  方法，如果 worker 不能和 master 进行沟通，那么 worker 就会终止。（还可以实现一个 pseudo-task，这个任务就是”please exit&quot;.</li>\n</ol>\n<h4 id=\"提示\"><a class=\"anchor\" href=\"#提示\">#</a> 提示</h4>\n<ol>\n<li><code>mr/worker.go</code>  通过 RPC 向 master 进行 task，master 发送一个还没进过 map 的文件名，然后 worker 就开始读取这个文件并调用 Map 函数。</li>\n<li>Map 和 Reduce 函数不用自己写，已经在 plugin 保重实现了。</li>\n<li>每次都要先 ``go build -buildmode=plugin ../mrapps/wc.go`</li>\n<li><code>mr-X-Y</code>  的方式给中间文件命名，X 值 Map task， Y 指 Reduce task。</li>\n<li>kv 键值对可以使用 json 文件格式进行存储。</li>\n<li>The map part of your worker can use the  <code>ihash(key)</code>  function (in  <code>worker.go</code> ) to pick the reduce task for a given key。也就是说 <code>ihash</code>  方式在 map 阶段就知道这个 key 该由哪个 reduce 进行处理。</li>\n<li><code>mrsequential.go</code>  的代码可以借鉴。<strong>注意 sort。</strong></li>\n<li>master 作为 RPC 服务器，它是并发的，所以到注意加锁。</li>\n<li><code>go build -race</code>  可以用作检查并发。</li>\n<li>所有的 map 执行完毕之后 reduce 才会执行，所以 reduce worker 需要等待。</li>\n<li>对于执行超时的 worker，master 需要重新分配任务。</li>\n<li><code>mrapps/crash.go</code>  用于检测崩溃回复。</li>\n<li>map 函数先用一个临时文件写中间数据，当所有的数据写完之后，在将文件名自动重命名。</li>\n</ol>\n<h4 id=\"遇到的问题\"><a class=\"anchor\" href=\"#遇到的问题\">#</a> 遇到的问题</h4>\n<ol>\n<li>taskstate 0 空闲 1 处理中 2 处理完毕</li>\n<li>坑点：只有当前 worker 执行完了一个 maptask 或者 reduce task 才能再执行 map 或者 reduce task。不能在一个 worker 机上同时并发执行多个 Map 或 reduce 函数。</li>\n<li>写中间文件需要使用 os.O_TRUNC，不然执行 sh 脚本会出错。</li>\n<li>最后的测试点只能用 Sock 方式进行 rpc，不能用 tcp 方式。</li>\n</ol>\n<h4 id=\"repo\"><a class=\"anchor\" href=\"#repo\">#</a> Repo</h4>\n<p>代码放在了 github 上：</p>\n<p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL1NvbmdsaW5MaWZlL01hcFJlZHVjZQ==\">MapReduce</span></p>\n<p>完成了所有测试点：</p>\n<p><img data-src=\"https://image-2021-wu.oss-cn-beijing.aliyuncs.com/blogs/picturesimage-20220224114038738.png\" alt=\"image-20220224114038738\" /></p>\n",
            "tags": [
                "分布式",
                "MIT6.824"
            ]
        }
    ]
}